{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Install missing python modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: skrebate in c:\\users\\miker\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (0.61)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\miker\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from skrebate) (0.23.2)\n",
      "Requirement already satisfied: numpy in c:\\users\\miker\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from skrebate) (1.19.1)\n",
      "Requirement already satisfied: scipy in c:\\users\\miker\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from skrebate) (1.5.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\miker\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from scikit-learn->skrebate) (2.1.0)\n",
      "Requirement already satisfied: joblib>=0.11 in c:\\users\\miker\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from scikit-learn->skrebate) (0.16.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 20.2.2; however, version 20.2.4 is available.\n",
      "You should consider upgrading via the 'c:\\users\\miker\\appdata\\local\\programs\\python\\python36\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install skrebate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Global imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from sklearn import datasets\n",
    "from ReliefF import ReliefF\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score \n",
    "from sklearn import svm\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pair plot of phenotype data (=discovering pairwise correlation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# growth_df=pd.read_csv('growth_SV', delimiter=\" \")\n",
    "# #factorize sex and population to use in PP\n",
    "# growth_df['sex'] = pd.factorize(growth_df.sex)[0]\n",
    "# growth_df['population'] = pd.factorize(growth_df.population)[0]\n",
    "# # Slicing out the phenotype data\n",
    "# data=growth_df.iloc[:, 0:9]\n",
    "# # Exclude indv from pairing, by putting it as index\n",
    "# data=data.set_index('indv')\n",
    "# # Sex 0 = male, sex 1 = unknown and sex 2 = female\n",
    "# # pop 0 = 2013B12, pop 1 = 2013B11, pop 2 = 2013B9 and pop 3 = 2013B10\n",
    "# sns.pairplot(data, hue=\"age\", palette=\"tab10\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Categorising fork_length\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load growth data for SV's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "growth_df=pd.read_csv('SNP_growth_50kb', delimiter=\" \")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>indv</th>\n",
       "      <th>sex</th>\n",
       "      <th>population</th>\n",
       "      <th>fork_length</th>\n",
       "      <th>age</th>\n",
       "      <th>spot_count</th>\n",
       "      <th>disease</th>\n",
       "      <th>deformity</th>\n",
       "      <th>nostril_count</th>\n",
       "      <th>LG1_50000_.</th>\n",
       "      <th>...</th>\n",
       "      <th>LG25_3750000_0/2</th>\n",
       "      <th>LG25_3750000_1/2</th>\n",
       "      <th>LG25_3750000_2/2</th>\n",
       "      <th>LG25_3800000_.</th>\n",
       "      <th>LG25_3800000_0/0</th>\n",
       "      <th>LG25_3800000_0/1</th>\n",
       "      <th>LG25_3800000_1/1</th>\n",
       "      <th>LG25_3800000_0/2</th>\n",
       "      <th>LG25_3800000_1/2</th>\n",
       "      <th>LG25_3800000_2/2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>27033489</td>\n",
       "      <td>male</td>\n",
       "      <td>2013B12</td>\n",
       "      <td>268.211388</td>\n",
       "      <td>3</td>\n",
       "      <td>53.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1255.0</td>\n",
       "      <td>174.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>27033489</td>\n",
       "      <td>male</td>\n",
       "      <td>2013B12</td>\n",
       "      <td>162.068598</td>\n",
       "      <td>1</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1255.0</td>\n",
       "      <td>174.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>83800743</td>\n",
       "      <td>unknown</td>\n",
       "      <td>2013B11</td>\n",
       "      <td>162.617027</td>\n",
       "      <td>1</td>\n",
       "      <td>39.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>9</td>\n",
       "      <td>...</td>\n",
       "      <td>14.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1291.0</td>\n",
       "      <td>170.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>83800743</td>\n",
       "      <td>unknown</td>\n",
       "      <td>2013B11</td>\n",
       "      <td>264.152366</td>\n",
       "      <td>3</td>\n",
       "      <td>30.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>9</td>\n",
       "      <td>...</td>\n",
       "      <td>14.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1291.0</td>\n",
       "      <td>170.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>140942470</td>\n",
       "      <td>unknown</td>\n",
       "      <td>2013B9</td>\n",
       "      <td>156.474088</td>\n",
       "      <td>1</td>\n",
       "      <td>44.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20</td>\n",
       "      <td>...</td>\n",
       "      <td>9.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1218.0</td>\n",
       "      <td>232.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>985661182</td>\n",
       "      <td>unknown</td>\n",
       "      <td>2013B9</td>\n",
       "      <td>149.724143</td>\n",
       "      <td>1</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>13</td>\n",
       "      <td>...</td>\n",
       "      <td>11.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1294.0</td>\n",
       "      <td>158.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>986994303</td>\n",
       "      <td>male</td>\n",
       "      <td>2013B12</td>\n",
       "      <td>250.116536</td>\n",
       "      <td>3</td>\n",
       "      <td>40.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>23</td>\n",
       "      <td>...</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1165.0</td>\n",
       "      <td>279.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>986994303</td>\n",
       "      <td>male</td>\n",
       "      <td>2013B12</td>\n",
       "      <td>148.071168</td>\n",
       "      <td>1</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>23</td>\n",
       "      <td>...</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1165.0</td>\n",
       "      <td>279.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>998916898</td>\n",
       "      <td>unknown</td>\n",
       "      <td>2013B9</td>\n",
       "      <td>168.723524</td>\n",
       "      <td>1</td>\n",
       "      <td>49.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1301.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>998916898</td>\n",
       "      <td>unknown</td>\n",
       "      <td>2013B9</td>\n",
       "      <td>277.517262</td>\n",
       "      <td>3</td>\n",
       "      <td>45.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1301.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>63 rows × 102657 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         indv      sex population  fork_length  age  spot_count  disease  \\\n",
       "0    27033489     male    2013B12   268.211388    3        53.0      2.0   \n",
       "1    27033489     male    2013B12   162.068598    1        54.0      0.0   \n",
       "2    83800743  unknown    2013B11   162.617027    1        39.0      0.0   \n",
       "3    83800743  unknown    2013B11   264.152366    3        30.0      2.0   \n",
       "4   140942470  unknown     2013B9   156.474088    1        44.0      0.0   \n",
       "..        ...      ...        ...          ...  ...         ...      ...   \n",
       "58  985661182  unknown     2013B9   149.724143    1        35.0      0.0   \n",
       "59  986994303     male    2013B12   250.116536    3        40.0      2.0   \n",
       "60  986994303     male    2013B12   148.071168    1        40.0      0.0   \n",
       "61  998916898  unknown     2013B9   168.723524    1        49.0      0.0   \n",
       "62  998916898  unknown     2013B9   277.517262    3        45.0      2.0   \n",
       "\n",
       "    deformity  nostril_count  LG1_50000_.  ...  LG25_3750000_0/2  \\\n",
       "0         0.0            1.0            1  ...              11.0   \n",
       "1         0.0            1.0            1  ...              11.0   \n",
       "2         0.0            2.0            9  ...              14.0   \n",
       "3         0.0            2.0            9  ...              14.0   \n",
       "4         0.0            1.0           20  ...               9.0   \n",
       "..        ...            ...          ...  ...               ...   \n",
       "58        0.0            2.0           13  ...              11.0   \n",
       "59        0.0            1.0           23  ...               9.0   \n",
       "60        0.0            1.0           23  ...               9.0   \n",
       "61        0.0            1.0            3  ...               6.0   \n",
       "62        0.0            1.0            3  ...               6.0   \n",
       "\n",
       "    LG25_3750000_1/2  LG25_3750000_2/2  LG25_3800000_.  LG25_3800000_0/0  \\\n",
       "0                1.0               6.0             3.0            1255.0   \n",
       "1                1.0               6.0             3.0            1255.0   \n",
       "2                3.0               3.0             1.0            1291.0   \n",
       "3                3.0               3.0             1.0            1291.0   \n",
       "4                4.0               3.0             3.0            1218.0   \n",
       "..               ...               ...             ...               ...   \n",
       "58               5.0               2.0             5.0            1294.0   \n",
       "59               2.0               5.0             1.0            1165.0   \n",
       "60               2.0               5.0             1.0            1165.0   \n",
       "61               6.0               3.0             1.0            1301.0   \n",
       "62               6.0               3.0             1.0            1301.0   \n",
       "\n",
       "    LG25_3800000_0/1  LG25_3800000_1/1  LG25_3800000_0/2  LG25_3800000_1/2  \\\n",
       "0              174.0              40.0              10.0               1.0   \n",
       "1              174.0              40.0              10.0               1.0   \n",
       "2              170.0              14.0               6.0               4.0   \n",
       "3              170.0              14.0               6.0               4.0   \n",
       "4              232.0              20.0               8.0               4.0   \n",
       "..               ...               ...               ...               ...   \n",
       "58             158.0              14.0               9.0               5.0   \n",
       "59             279.0              22.0              16.0               3.0   \n",
       "60             279.0              22.0              16.0               3.0   \n",
       "61             150.0              13.0              12.0               7.0   \n",
       "62             150.0              13.0              12.0               7.0   \n",
       "\n",
       "    LG25_3800000_2/2  \n",
       "0                5.0  \n",
       "1                5.0  \n",
       "2                3.0  \n",
       "3                3.0  \n",
       "4                3.0  \n",
       "..               ...  \n",
       "58               1.0  \n",
       "59               3.0  \n",
       "60               3.0  \n",
       "61               5.0  \n",
       "62               5.0  \n",
       "\n",
       "[63 rows x 102657 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "growth_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Split data in year 1 and year 3 data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "growth_y1 = growth_df.loc[(growth_df['age'] == 1)]\n",
    "growth_y3 = growth_df.loc[(growth_df['age'] == 3)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bin into small --> medium --> big"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Year 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-4-500e8c2916d0>:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  small['fork_length']=\"small\"\n",
      "<ipython-input-4-500e8c2916d0>:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  medium['fork_length']=\"medium\"\n",
      "<ipython-input-4-500e8c2916d0>:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  big['fork_length']=\"big\"\n"
     ]
    }
   ],
   "source": [
    "small=growth_y1.loc[(growth_y1['fork_length'] >= min(growth_y1.fork_length)) & (growth_y1['fork_length'] <= growth_y1.fork_length.quantile(0.33))]\n",
    "small['fork_length']=\"small\"\n",
    "small\n",
    "\n",
    "\n",
    "medium=growth_y1.loc[(growth_y1['fork_length'] > growth_y1.fork_length.quantile(0.33)) & (growth_y1['fork_length'] <= growth_y1.fork_length.quantile(0.66))]\n",
    "medium['fork_length']=\"medium\"\n",
    "medium\n",
    "\n",
    "big=growth_y1.loc[growth_y1['fork_length'] > growth_y1.fork_length.quantile(0.66)]\n",
    "big['fork_length']=\"big\"\n",
    "big\n",
    "\n",
    "small_medium=small.append(medium)\n",
    "binned_y1=small_medium.append(big)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Year 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-5-3ebd253edfbf>:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  small['fork_length']=\"small\"\n",
      "<ipython-input-5-3ebd253edfbf>:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  medium['fork_length']=\"medium\"\n",
      "<ipython-input-5-3ebd253edfbf>:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  big['fork_length']=\"big\"\n"
     ]
    }
   ],
   "source": [
    "small=growth_y3.loc[(growth_y3['fork_length'] >= min(growth_y3.fork_length)) & (growth_y3['fork_length'] <= growth_y3.fork_length.quantile(0.33))]\n",
    "small['fork_length']=\"small\"\n",
    "small\n",
    "\n",
    "\n",
    "medium=growth_y3.loc[(growth_y3['fork_length'] > growth_y3.fork_length.quantile(0.33)) & (growth_y3['fork_length'] <= growth_y3.fork_length.quantile(0.66))]\n",
    "medium['fork_length']=\"medium\"\n",
    "medium\n",
    "\n",
    "big=growth_y3.loc[growth_y3['fork_length'] > growth_y3.fork_length.quantile(0.66)]\n",
    "big['fork_length']=\"big\"\n",
    "big\n",
    "\n",
    "small_medium=small.append(medium)\n",
    "binned_y3=small_medium.append(big)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Classifiers with all features and year 3 data ---\n",
      "\n",
      "KNN 0.375\n",
      "Naive Bayes 0.4375\n",
      "Logistic regression 0.375\n",
      "Random forest 0.3125\n",
      "--- Classifiers with all features and year 1 data ---\n",
      "\n",
      "KNN 0.3125\n",
      "Naive Bayes 0.3125\n",
      "Logistic regression 0.25\n",
      "Random forest 0.3125\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['big', 'big', 'big', 'big', 'big', 'big', 'big', 'big', 'medium',\n",
       "       'big', 'big', 'small', 'big', 'big', 'big', 'big'], dtype=object)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "binned_y3['sex'] = pd.factorize(binned_y3.sex)[0]\n",
    "binned_y3['population'] = pd.factorize(binned_y3.population)[0]\n",
    "x=binned_y3.drop('fork_length',1)\n",
    "y = binned_y3.fork_length\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.5,random_state=2)\n",
    "\n",
    "print(\"--- Classifiers with all features and year 3 data ---\\n\")\n",
    "classifier = KNeighborsClassifier(n_neighbors=5, p=2, metric='minkowski')\n",
    "classifier.fit(x_train, y_train)\n",
    "y_pred = classifier.predict(x_test)\n",
    "print(\"KNN\", accuracy_score(y_test, y_pred))\n",
    "\n",
    "\n",
    "classifier = GaussianNB()\n",
    "classifier.fit(x_train, y_train)\n",
    "y_pred = classifier.predict(x_test)\n",
    "print(\"Naive Bayes\", accuracy_score(y_test, y_pred))\n",
    "\n",
    "clf = LogisticRegression(random_state=0).fit(x_train, y_train)\n",
    "pred = clf.predict(x_test)\n",
    "print(\"Logistic regression\", accuracy_score(y_test, pred))\n",
    "\n",
    "ranfor = RandomForestClassifier(n_estimators = 150, criterion = 'entropy', random_state = 5, max_depth = 200)\n",
    "ranfor.fit(x_train, y_train)\n",
    "pred_ranfor = ranfor.predict(x_test)\n",
    "print(\"Random forest\", accuracy_score(y_test, pred_ranfor))\n",
    "pred_ranfor\n",
    "\n",
    "\n",
    "binned_y1['sex'] = pd.factorize(binned_y1.sex)[0]\n",
    "binned_y1['population'] = pd.factorize(binned_y1.population)[0]\n",
    "x=binned_y1.drop('fork_length',1)\n",
    "y = binned_y1.fork_length\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.5,random_state=2)\n",
    "\n",
    "print(\"--- Classifiers with all features and year 1 data ---\\n\")\n",
    "classifier = KNeighborsClassifier(n_neighbors=5, p=2, metric='minkowski')\n",
    "classifier.fit(x_train, y_train)\n",
    "y_pred = classifier.predict(x_test)\n",
    "print(\"KNN\", accuracy_score(y_test, y_pred))\n",
    "\n",
    "\n",
    "classifier = GaussianNB()\n",
    "classifier.fit(x_train, y_train)\n",
    "y_pred = classifier.predict(x_test)\n",
    "print(\"Naive Bayes\", accuracy_score(y_test, y_pred))\n",
    "\n",
    "clf = LogisticRegression(random_state=0).fit(x_train, y_train)\n",
    "pred = clf.predict(x_test)\n",
    "print(\"Logistic regression\", accuracy_score(y_test, pred))\n",
    "\n",
    "ranfor = RandomForestClassifier(n_estimators = 150, criterion = 'entropy', random_state = 5, max_depth = 200)\n",
    "ranfor.fit(x_train, y_train)\n",
    "pred_ranfor = ranfor.predict(x_test)\n",
    "print(\"Random forest\", accuracy_score(y_test, pred_ranfor))\n",
    "pred_ranfor\n",
    "\n",
    "# sv = svm.SVC(kernel='linear')\n",
    "# sv.fit(x_train, y_train)\n",
    "# pred_svm = sv.predict(x_test)\n",
    "# print(\"SVM\",accuracy_score(y_test, pred_svm))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Do relief F feature selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview of target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "big       11\n",
      "small     11\n",
      "medium    10\n",
      "Name: fork_length, dtype: int64\n",
      "big       11\n",
      "small     10\n",
      "medium    10\n",
      "Name: fork_length, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(binned_y1['fork_length'].value_counts())\n",
    "print(binned_y3['fork_length'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start with year 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created distance array in 3.404171943664551 seconds.\n",
      "Feature scoring under way ...\n",
      "Completed scoring in 252.17766094207764 seconds.\n",
      "Created distance array in 1.4953465461730957 seconds.\n",
      "Feature scoring under way ...\n",
      "Completed scoring in 121.7877140045166 seconds.\n",
      "Created distance array in 0.7127585411071777 seconds.\n",
      "Feature scoring under way ...\n",
      "Completed scoring in 58.99551868438721 seconds.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from skrebate.turf import TuRF\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "binned_y1['sex'] = pd.factorize(binned_y1.sex)[0]\n",
    "binned_y1['population'] = pd.factorize(binned_y1.population)[0]\n",
    "genetic_data=binned_y1\n",
    "features, labels = genetic_data.drop('fork_length', axis=1).values, genetic_data['fork_length'].values\n",
    "headers = list(genetic_data.drop(\"fork_length\", axis=1))\n",
    "fs1 = TuRF(core_algorithm=\"ReliefF\", n_features_to_select=2, pct=0.5,verbose=True)\n",
    "fs1.fit(features, labels, headers)\n",
    "reliefdict1={}\n",
    "for feature_name, feature_score in zip(genetic_data.drop('fork_length', axis=1).columns, fs1.feature_importances_):\n",
    "    reliefdict1[feature_score]=feature_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get top 25 scores year 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['LG11_13550000_1/1', 'LG19_20300000_.', 'LG16_11350000_1/1', 'LG21_800000_.', 'LG5_3050000_1/1', 'LG14_19200000_.', 'LG20_20650000_0/1', 'LG19_26250000_2/2', 'LG7_31450000_0/0', 'LG7_31450000_0/0', 'LG19_15250000_1/1', 'LG15_100000_.', 'LG16_17450000_0/2', 'LG20_20650000_0/0', 'LG11_15500000_.', 'LG19_20300000_0/1', 'LG11_1400000_0/0', 'LG13_30800000_2/2', 'LG16_13900000_0/1', 'LG1_1700000_0/2', 'LG1_1700000_0/2', 'LG11_13550000_0/0', 'LG13_25650000_1/1', 'LG13_8650000_.', 'LG7_25300000_1/2']\n"
     ]
    }
   ],
   "source": [
    "# print(reliefdict)\n",
    "y1_relief_top=[]\n",
    "for value in fs1.top_features_[0:25]:\n",
    "    score=fs1.feature_importances_[value]\n",
    "    y1_relief_top.append(reliefdict1[score])\n",
    "    \n",
    "print(y1_relief_top)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get prediction year 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Classifiers with TuRF Relief-F top 25 features and year 1 data ---\n",
      "\n",
      "KNN 0.8125\n",
      "Naive Bayes 0.5\n",
      "Logistic regression 0.625\n",
      "Random forest 0.6875\n",
      "SVM 0.5625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\miker\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    }
   ],
   "source": [
    "x=binned_y1[y1_relief_top]\n",
    "y = binned_y1.fork_length\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.5,random_state=2)\n",
    "\n",
    "print(\"--- Classifiers with TuRF Relief-F top\",str(len(y1_relief_top)), \"features and year 1 data ---\\n\")\n",
    "classifier = KNeighborsClassifier(n_neighbors=5, p=2, metric='minkowski')\n",
    "classifier.fit(x_train, y_train)\n",
    "y_pred = classifier.predict(x_test)\n",
    "print(\"KNN\", accuracy_score(y_test, y_pred))\n",
    "\n",
    "\n",
    "classifier = GaussianNB()\n",
    "classifier.fit(x_train, y_train)\n",
    "y_pred = classifier.predict(x_test)\n",
    "print(\"Naive Bayes\", accuracy_score(y_test, y_pred))\n",
    "\n",
    "clf = LogisticRegression(random_state=0).fit(x_train, y_train)\n",
    "pred = clf.predict(x_test)\n",
    "print(\"Logistic regression\", accuracy_score(y_test, pred))\n",
    "\n",
    "ranfor = RandomForestClassifier(n_estimators = 150, criterion = 'entropy', random_state = 5, max_depth = 200)\n",
    "ranfor.fit(x_train, y_train)\n",
    "pred_ranfor = ranfor.predict(x_test)\n",
    "print(\"Random forest\", accuracy_score(y_test, pred_ranfor))\n",
    "pred_ranfor\n",
    "\n",
    "sv = svm.SVC(kernel='linear')\n",
    "sv.fit(x_train, y_train)\n",
    "pred_svm = sv.predict(x_test)\n",
    "print(\"SVM\",accuracy_score(y_test, pred_svm))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now do year 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created distance array in 3.227729320526123 seconds.\n",
      "Feature scoring under way ...\n",
      "Completed scoring in 230.61371421813965 seconds.\n",
      "Created distance array in 1.4723265171051025 seconds.\n",
      "Feature scoring under way ...\n",
      "Completed scoring in 112.87941217422485 seconds.\n",
      "Created distance array in 0.6821603775024414 seconds.\n",
      "Feature scoring under way ...\n",
      "Completed scoring in 56.1529278755188 seconds.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from skrebate.turf import TuRF\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "binned_y3['sex'] = pd.factorize(binned_y3.sex)[0]\n",
    "binned_y3['population'] = pd.factorize(binned_y3.population)[0]\n",
    "genetic_data=binned_y3\n",
    "features, labels = genetic_data.drop('fork_length', axis=1).values, genetic_data['fork_length'].values\n",
    "headers = list(genetic_data.drop(\"fork_length\", axis=1))\n",
    "fs3 = TuRF(core_algorithm=\"ReliefF\", n_features_to_select=2, pct=0.5,verbose=True)\n",
    "fs3.fit(features, labels, headers)\n",
    "reliefdict3={}\n",
    "for feature_name, feature_score in zip(genetic_data.drop('fork_length', axis=1).columns, fs3.feature_importances_):\n",
    "    reliefdict3[feature_score]=feature_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get top 25 year 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['LG1_28500000_1/2', 'LG1_28500000_2/2', 'LG20_14100000_0/0', 'LG1_28500000_1/1', 'LG12_4450000_0/0', 'LG19_9700000_0/2', 'LG8_36750000_1/1', 'LG8_33050000_0/0', 'LG8_33800000_0/0', 'LG25_3800000_2/2', 'LG7_33600000_2/2', 'LG19_9700000_2/2', 'LG21_2000000_.', 'LG19_9700000_0/1', 'LG21_25650000_.', 'LG7_27650000_2/2', 'LG8_34950000_0/2', 'LG7_11950000_1/2', 'LG10_32200000_.', 'LG10_17550000_0/1', 'LG17_20800000_1/2', 'LG20_20650000_0/1', 'LG19_14150000_.', 'LG7_25300000_1/2', 'LG17_24150000_.']\n"
     ]
    }
   ],
   "source": [
    "# print(reliefdict)\n",
    "y3_relief_top=[]\n",
    "for value in fs3.top_features_[0:25]:\n",
    "    score=fs3.feature_importances_[value]\n",
    "    y3_relief_top.append(reliefdict3[score])\n",
    "    \n",
    "print(y3_relief_top)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get prediction year 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Classifiers with TuRF Relief-F top 25 features and year 3 data ---\n",
      "\n",
      "KNN 0.75\n",
      "Naive Bayes 0.875\n",
      "Logistic regression 0.6875\n",
      "Random forest 0.875\n",
      "SVM 0.625\n"
     ]
    }
   ],
   "source": [
    "x=binned_y3[y3_relief_top]\n",
    "y = binned_y3.fork_length\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.5,random_state=2)\n",
    "\n",
    "print(\"--- Classifiers with TuRF Relief-F top\",str(len(y3_relief_top)), \"features and year 3 data ---\\n\")\n",
    "classifier = KNeighborsClassifier(n_neighbors=5, p=2, metric='minkowski')\n",
    "classifier.fit(x_train, y_train)\n",
    "y_pred = classifier.predict(x_test)\n",
    "print(\"KNN\", accuracy_score(y_test, y_pred))\n",
    "\n",
    "classifier = GaussianNB()\n",
    "classifier.fit(x_train, y_train)\n",
    "y_pred = classifier.predict(x_test)\n",
    "print(\"Naive Bayes\", accuracy_score(y_test, y_pred))\n",
    "\n",
    "clf = LogisticRegression(random_state=0,max_iter=2000).fit(x_train, y_train)\n",
    "pred = clf.predict(x_test)\n",
    "print(\"Logistic regression\", accuracy_score(y_test, pred))\n",
    "\n",
    "ranfor = RandomForestClassifier(n_estimators = 150, criterion = 'entropy', random_state = 5, max_depth = 200)\n",
    "ranfor.fit(x_train, y_train)\n",
    "pred_ranfor = ranfor.predict(x_test)\n",
    "print(\"Random forest\", accuracy_score(y_test, pred_ranfor))\n",
    "pred_ranfor\n",
    "\n",
    "sv = svm.SVC(kernel='linear')\n",
    "sv.fit(x_train, y_train)\n",
    "pred_svm = sv.predict(x_test)\n",
    "print(\"SVM\",accuracy_score(y_test, pred_svm))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Year 1 chi-square feature selection and prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Classifiers with chi-square top 25 features and year 1 data ---\n",
      "\n",
      "KNN 0.5\n",
      "Naive Bayes 0.6875\n",
      "Logistic regression 0.5\n",
      "Random forest 0.4375\n",
      "SVM 0.4375\n"
     ]
    }
   ],
   "source": [
    "binned_y1['sex'] = pd.factorize(binned_y1.sex)[0]\n",
    "binned_y1['population'] = pd.factorize(binned_y1.population)[0]\n",
    "y = binned_y1.fork_length\n",
    "X = binned_y1.drop(columns=[\"fork_length\"])\n",
    "bestfeatures = SelectKBest(score_func=chi2, k=10)\n",
    "bestfeatures\n",
    "fit = bestfeatures.fit(X,y)\n",
    "dfscores = pd.DataFrame(fit.scores_)\n",
    "dfcolumns = pd.DataFrame(X.columns)\n",
    "featureScores = pd.concat([dfcolumns,dfscores],axis=1)\n",
    "featureScores.columns = ['Specs','Score']  \n",
    "var=str(featureScores.nlargest(26,'Score'))\n",
    "var.split()\n",
    "data_listc1=[]\n",
    "for values in var.split():\n",
    "    if \"LG\" in values:\n",
    "        data_listc1.append(values)\n",
    "x=X[data_listc1]\n",
    "y = binned_y1.fork_length\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.5,random_state=2)\n",
    "\n",
    "\n",
    "print(\"--- Classifiers with chi-square top\",str(len(data_listc1)), \"features and year 1 data ---\\n\")\n",
    "classifier = KNeighborsClassifier(n_neighbors=5, p=2, metric='minkowski')\n",
    "classifier.fit(x_train, y_train)\n",
    "y_pred = classifier.predict(x_test)\n",
    "print(\"KNN\", accuracy_score(y_test, y_pred))\n",
    "\n",
    "\n",
    "classifier = GaussianNB()\n",
    "classifier.fit(x_train, y_train)\n",
    "y_pred = classifier.predict(x_test)\n",
    "print(\"Naive Bayes\", accuracy_score(y_test, y_pred))\n",
    "\n",
    "clf = LogisticRegression(random_state=0,max_iter=2000).fit(x_train, y_train)\n",
    "pred = clf.predict(x_test)\n",
    "print(\"Logistic regression\", accuracy_score(y_test, pred))\n",
    "\n",
    "ranfor = RandomForestClassifier(n_estimators = 150, criterion = 'entropy', random_state = 5, max_depth = 200)\n",
    "ranfor.fit(x_train, y_train)\n",
    "pred_ranfor = ranfor.predict(x_test)\n",
    "print(\"Random forest\", accuracy_score(y_test, pred_ranfor))\n",
    "pred_ranfor\n",
    "\n",
    "sv = svm.SVC(kernel='linear')\n",
    "sv.fit(x_train, y_train)\n",
    "pred_svm = sv.predict(x_test)\n",
    "print(\"SVM\",accuracy_score(y_test, pred_svm))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Year 3 chi-square feature selection and prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Classifiers with chi-square top 25 features and year 3 data ---\n",
      "\n",
      "KNN 0.3125\n",
      "Naive Bayes 0.5\n",
      "Logistic regression 0.5625\n",
      "Random forest 0.5625\n",
      "SVM 0.5\n"
     ]
    }
   ],
   "source": [
    "binned_y3['sex'] = pd.factorize(binned_y3.sex)[0]\n",
    "binned_y3['population'] = pd.factorize(binned_y3.population)[0]\n",
    "y = binned_y3.fork_length\n",
    "X = binned_y3.drop(columns=[\"fork_length\"])\n",
    "bestfeatures = SelectKBest(score_func=chi2, k=10)\n",
    "bestfeatures\n",
    "fit = bestfeatures.fit(X,y)\n",
    "dfscores = pd.DataFrame(fit.scores_)\n",
    "dfcolumns = pd.DataFrame(X.columns)\n",
    "featureScores = pd.concat([dfcolumns,dfscores],axis=1)\n",
    "featureScores.columns = ['Specs','Score']  \n",
    "var=str(featureScores.nlargest(26,'Score'))\n",
    "var.split()\n",
    "data_listc3=[]\n",
    "for values in var.split():\n",
    "    if \"LG\" in values:\n",
    "        data_listc3.append(values)\n",
    "x=X[data_listc3]\n",
    "y = binned_y3.fork_length\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.5,random_state=2)\n",
    "\n",
    "\n",
    "print(\"--- Classifiers with chi-square top\",str(len(data_listc3)), \"features and year 3 data ---\\n\")\n",
    "classifier = KNeighborsClassifier(n_neighbors=5, p=2, metric='minkowski')\n",
    "classifier.fit(x_train, y_train)\n",
    "y_pred = classifier.predict(x_test)\n",
    "print(\"KNN\", accuracy_score(y_test, y_pred))\n",
    "\n",
    "\n",
    "classifier = GaussianNB()\n",
    "classifier.fit(x_train, y_train)\n",
    "y_pred = classifier.predict(x_test)\n",
    "print(\"Naive Bayes\", accuracy_score(y_test, y_pred))\n",
    "\n",
    "clf = LogisticRegression(random_state=0,max_iter=2000).fit(x_train, y_train)\n",
    "pred = clf.predict(x_test)\n",
    "print(\"Logistic regression\", accuracy_score(y_test, pred))\n",
    "\n",
    "ranfor = RandomForestClassifier(n_estimators = 150, criterion = 'entropy', random_state = 5, max_depth = 200)\n",
    "ranfor.fit(x_train, y_train)\n",
    "pred_ranfor = ranfor.predict(x_test)\n",
    "print(\"Random forest\", accuracy_score(y_test, pred_ranfor))\n",
    "pred_ranfor\n",
    "\n",
    "sv = svm.SVC(kernel='linear')\n",
    "sv.fit(x_train, y_train)\n",
    "pred_svm = sv.predict(x_test)\n",
    "print(\"SVM\",accuracy_score(y_test, pred_svm))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mutual information feature selection year 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Classifiers with mutual information top 25 features and year 1 data ---\n",
      "\n",
      "KNN 0.375\n",
      "Naive Bayes 0.625\n",
      "Logistic regression 0.625\n",
      "Random forest 0.625\n",
      "SVM 0.5\n"
     ]
    }
   ],
   "source": [
    "binned_y1['sex'] = pd.factorize(binned_y1.sex)[0]\n",
    "binned_y1['population'] = pd.factorize(binned_y1.population)[0]\n",
    "y = binned_y1.fork_length\n",
    "X = binned_y1.drop(columns=[\"fork_length\"])\n",
    "bestfeatures = SelectKBest(score_func=mutual_info_classif, k=10)\n",
    "bestfeatures\n",
    "fit = bestfeatures.fit(X,y)\n",
    "dfscores = pd.DataFrame(fit.scores_)\n",
    "dfcolumns = pd.DataFrame(X.columns)\n",
    "featureScores = pd.concat([dfcolumns,dfscores],axis=1)\n",
    "featureScores.columns = ['Specs','Score']  \n",
    "var=str(featureScores.nlargest(25,'Score'))\n",
    "var.split()\n",
    "data_listm1=[]\n",
    "for values in var.split():\n",
    "    if \"LG\" in values:\n",
    "        data_listm1.append(values)\n",
    "x=X[data_listm1]\n",
    "y = binned_y1.fork_length\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.5,random_state=2)\n",
    "\n",
    "\n",
    "print(\"--- Classifiers with mutual information top\",str(len(data_listm1)), \"features and year 1 data ---\\n\")\n",
    "classifier = KNeighborsClassifier(n_neighbors=5, p=2, metric='minkowski')\n",
    "classifier.fit(x_train, y_train)\n",
    "y_pred = classifier.predict(x_test)\n",
    "print(\"KNN\", accuracy_score(y_test, y_pred))\n",
    "\n",
    "\n",
    "classifier = GaussianNB()\n",
    "classifier.fit(x_train, y_train)\n",
    "y_pred = classifier.predict(x_test)\n",
    "print(\"Naive Bayes\", accuracy_score(y_test, y_pred))\n",
    "\n",
    "clf = LogisticRegression(random_state=0,max_iter=2000).fit(x_train, y_train)\n",
    "pred = clf.predict(x_test)\n",
    "print(\"Logistic regression\", accuracy_score(y_test, pred))\n",
    "\n",
    "ranfor = RandomForestClassifier(n_estimators = 150, criterion = 'entropy', random_state = 5, max_depth = 200)\n",
    "ranfor.fit(x_train, y_train)\n",
    "pred_ranfor = ranfor.predict(x_test)\n",
    "print(\"Random forest\", accuracy_score(y_test, pred_ranfor))\n",
    "pred_ranfor\n",
    "\n",
    "sv = svm.SVC(kernel='linear')\n",
    "sv.fit(x_train, y_train)\n",
    "pred_svm = sv.predict(x_test)\n",
    "print(\"SVM\",accuracy_score(y_test, pred_svm))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mutual information feature selection year 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Classifiers with mutual information top 25 features and year 3 data ---\n",
      "\n",
      "KNN 0.4375\n",
      "Naive Bayes 0.75\n",
      "Logistic regression 0.5625\n",
      "Random forest 1.0\n",
      "SVM 0.5\n"
     ]
    }
   ],
   "source": [
    "binned_y3['sex'] = pd.factorize(binned_y3.sex)[0]\n",
    "binned_y3['population'] = pd.factorize(binned_y3.population)[0]\n",
    "y = binned_y3.fork_length\n",
    "X = binned_y3.drop(columns=[\"fork_length\"])\n",
    "bestfeatures = SelectKBest(score_func=mutual_info_classif, k=10)\n",
    "bestfeatures\n",
    "fit = bestfeatures.fit(X,y)\n",
    "dfscores = pd.DataFrame(fit.scores_)\n",
    "dfcolumns = pd.DataFrame(X.columns)\n",
    "featureScores = pd.concat([dfcolumns,dfscores],axis=1)\n",
    "featureScores.columns = ['Specs','Score']  \n",
    "var=str(featureScores.nlargest(25,'Score'))\n",
    "var.split()\n",
    "data_listm3=[]\n",
    "for values in var.split():\n",
    "    if \"LG\" in values:\n",
    "        data_listm3.append(values)\n",
    "x=X[data_listm3]\n",
    "y = binned_y3.fork_length\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.5,random_state=2)\n",
    "\n",
    "\n",
    "print(\"--- Classifiers with mutual information top\",str(len(data_listm3)), \"features and year 3 data ---\\n\")\n",
    "classifier = KNeighborsClassifier(n_neighbors=5, p=2, metric='minkowski')\n",
    "classifier.fit(x_train, y_train)\n",
    "y_pred = classifier.predict(x_test)\n",
    "print(\"KNN\", accuracy_score(y_test, y_pred))\n",
    "\n",
    "\n",
    "classifier = GaussianNB()\n",
    "classifier.fit(x_train, y_train)\n",
    "y_pred = classifier.predict(x_test)\n",
    "print(\"Naive Bayes\", accuracy_score(y_test, y_pred))\n",
    "\n",
    "clf = LogisticRegression(random_state=0,max_iter=2000).fit(x_train, y_train)\n",
    "pred = clf.predict(x_test)\n",
    "print(\"Logistic regression\", accuracy_score(y_test, pred))\n",
    "\n",
    "ranfor = RandomForestClassifier(n_estimators = 150, criterion = 'entropy', random_state = 5, max_depth = 200)\n",
    "ranfor.fit(x_train, y_train)\n",
    "pred_ranfor = ranfor.predict(x_test)\n",
    "print(\"Random forest\", accuracy_score(y_test, pred_ranfor))\n",
    "pred_ranfor\n",
    "\n",
    "sv = svm.SVC(kernel='linear')\n",
    "sv.fit(x_train, y_train)\n",
    "pred_svm = sv.predict(x_test)\n",
    "print(\"SVM\",accuracy_score(y_test, pred_svm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32    medium\n",
       "5      small\n",
       "46       big\n",
       "41       big\n",
       "16    medium\n",
       "59     small\n",
       "6      small\n",
       "0        big\n",
       "49       big\n",
       "51    medium\n",
       "25    medium\n",
       "3     medium\n",
       "29     small\n",
       "39     small\n",
       "19     small\n",
       "8        big\n",
       "Name: fork_length, dtype: object"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

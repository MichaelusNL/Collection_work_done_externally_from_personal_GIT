{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"oi\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Install missing python modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: skrebate in c:\\users\\hramzr\\anaconda3\\lib\\site-packages (0.61)\n",
      "Requirement already satisfied: scipy in c:\\users\\hramzr\\anaconda3\\lib\\site-packages (from skrebate) (1.5.0)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\hramzr\\anaconda3\\lib\\site-packages (from skrebate) (0.23.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\hramzr\\anaconda3\\lib\\site-packages (from skrebate) (1.18.5)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\hramzr\\anaconda3\\lib\\site-packages (from scikit-learn->skrebate) (2.1.0)\n",
      "Requirement already satisfied: joblib>=0.11 in c:\\users\\hramzr\\anaconda3\\lib\\site-packages (from scikit-learn->skrebate) (0.16.0)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install skrebate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Global imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from sklearn import datasets\n",
    "from ReliefF import ReliefF\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score \n",
    "from sklearn import svm\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pair plot of phenotype data (=discovering pairwise correlation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# growth_df=pd.read_csv('growth_SV', delimiter=\" \")\n",
    "# #factorize sex and population to use in PP\n",
    "# growth_df['sex'] = pd.factorize(growth_df.sex)[0]\n",
    "# growth_df['population'] = pd.factorize(growth_df.population)[0]\n",
    "# # Slicing out the phenotype data\n",
    "# data=growth_df.iloc[:, 0:9]\n",
    "# # Exclude indv from pairing, by putting it as index\n",
    "# data=data.set_index('indv')\n",
    "# # Sex 0 = male, sex 1 = unknown and sex 2 = female\n",
    "# # pop 0 = 2013B12, pop 1 = 2013B11, pop 2 = 2013B9 and pop 3 = 2013B10\n",
    "# sns.pairplot(data, hue=\"age\", palette=\"tab10\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Categorising fork_length\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load growth data for SV's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "growth_df=pd.read_csv('SV_growth_50kb_1kb_5', delimiter=\" \")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>indv</th>\n",
       "      <th>sex</th>\n",
       "      <th>population</th>\n",
       "      <th>fork_length</th>\n",
       "      <th>age</th>\n",
       "      <th>spot_count</th>\n",
       "      <th>disease</th>\n",
       "      <th>deformity</th>\n",
       "      <th>nostril_count</th>\n",
       "      <th>LG1_dels_50000</th>\n",
       "      <th>...</th>\n",
       "      <th>LG25_ins_3700000</th>\n",
       "      <th>LG25_invs_3700000</th>\n",
       "      <th>LG25_dels_3750000</th>\n",
       "      <th>LG25_dups_3750000</th>\n",
       "      <th>LG25_ins_3750000</th>\n",
       "      <th>LG25_invs_3750000</th>\n",
       "      <th>LG25_dels_3800000</th>\n",
       "      <th>LG25_dups_3800000</th>\n",
       "      <th>LG25_ins_3800000</th>\n",
       "      <th>LG25_invs_3800000</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>27033489</td>\n",
       "      <td>male</td>\n",
       "      <td>2013B12</td>\n",
       "      <td>268.211388</td>\n",
       "      <td>3</td>\n",
       "      <td>53.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>27033489</td>\n",
       "      <td>male</td>\n",
       "      <td>2013B12</td>\n",
       "      <td>162.068598</td>\n",
       "      <td>1</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>83800743</td>\n",
       "      <td>unknown</td>\n",
       "      <td>2013B11</td>\n",
       "      <td>162.617027</td>\n",
       "      <td>1</td>\n",
       "      <td>39.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>83800743</td>\n",
       "      <td>unknown</td>\n",
       "      <td>2013B11</td>\n",
       "      <td>264.152366</td>\n",
       "      <td>3</td>\n",
       "      <td>30.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>140942470</td>\n",
       "      <td>unknown</td>\n",
       "      <td>2013B9</td>\n",
       "      <td>156.474088</td>\n",
       "      <td>1</td>\n",
       "      <td>44.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>985661182</td>\n",
       "      <td>unknown</td>\n",
       "      <td>2013B9</td>\n",
       "      <td>149.724143</td>\n",
       "      <td>1</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>986994303</td>\n",
       "      <td>male</td>\n",
       "      <td>2013B12</td>\n",
       "      <td>250.116536</td>\n",
       "      <td>3</td>\n",
       "      <td>40.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>986994303</td>\n",
       "      <td>male</td>\n",
       "      <td>2013B12</td>\n",
       "      <td>148.071168</td>\n",
       "      <td>1</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>998916898</td>\n",
       "      <td>unknown</td>\n",
       "      <td>2013B9</td>\n",
       "      <td>168.723524</td>\n",
       "      <td>1</td>\n",
       "      <td>49.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>998916898</td>\n",
       "      <td>unknown</td>\n",
       "      <td>2013B9</td>\n",
       "      <td>277.517262</td>\n",
       "      <td>3</td>\n",
       "      <td>45.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>63 rows × 58665 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         indv      sex population  fork_length  age  spot_count  disease  \\\n",
       "0    27033489     male    2013B12   268.211388    3        53.0      2.0   \n",
       "1    27033489     male    2013B12   162.068598    1        54.0      0.0   \n",
       "2    83800743  unknown    2013B11   162.617027    1        39.0      0.0   \n",
       "3    83800743  unknown    2013B11   264.152366    3        30.0      2.0   \n",
       "4   140942470  unknown     2013B9   156.474088    1        44.0      0.0   \n",
       "..        ...      ...        ...          ...  ...         ...      ...   \n",
       "58  985661182  unknown     2013B9   149.724143    1        35.0      0.0   \n",
       "59  986994303     male    2013B12   250.116536    3        40.0      2.0   \n",
       "60  986994303     male    2013B12   148.071168    1        40.0      0.0   \n",
       "61  998916898  unknown     2013B9   168.723524    1        49.0      0.0   \n",
       "62  998916898  unknown     2013B9   277.517262    3        45.0      2.0   \n",
       "\n",
       "    deformity  nostril_count  LG1_dels_50000  ...  LG25_ins_3700000  \\\n",
       "0         0.0            1.0               2  ...                 1   \n",
       "1         0.0            1.0               2  ...                 1   \n",
       "2         0.0            2.0               4  ...                 1   \n",
       "3         0.0            2.0               4  ...                 1   \n",
       "4         0.0            1.0               4  ...                 0   \n",
       "..        ...            ...             ...  ...               ...   \n",
       "58        0.0            2.0               4  ...                 1   \n",
       "59        0.0            1.0               4  ...                 0   \n",
       "60        0.0            1.0               4  ...                 0   \n",
       "61        0.0            1.0               3  ...                 1   \n",
       "62        0.0            1.0               3  ...                 1   \n",
       "\n",
       "    LG25_invs_3700000  LG25_dels_3750000  LG25_dups_3750000  LG25_ins_3750000  \\\n",
       "0                   0                  2                  0                 0   \n",
       "1                   0                  2                  0                 0   \n",
       "2                   0                  1                  0                 0   \n",
       "3                   0                  1                  0                 0   \n",
       "4                   0                  0                  0                 0   \n",
       "..                ...                ...                ...               ...   \n",
       "58                  0                  1                  0                 0   \n",
       "59                  0                  1                  0                 0   \n",
       "60                  0                  1                  0                 0   \n",
       "61                  0                  0                  0                 0   \n",
       "62                  0                  0                  0                 0   \n",
       "\n",
       "    LG25_invs_3750000  LG25_dels_3800000  LG25_dups_3800000  LG25_ins_3800000  \\\n",
       "0                   0                  1                  0                 1   \n",
       "1                   0                  1                  0                 1   \n",
       "2                   0                  2                  0                 0   \n",
       "3                   0                  2                  0                 0   \n",
       "4                   0                  2                  0                 0   \n",
       "..                ...                ...                ...               ...   \n",
       "58                  0                  1                  0                 0   \n",
       "59                  0                  2                  0                 0   \n",
       "60                  0                  2                  0                 0   \n",
       "61                  0                  2                  0                 0   \n",
       "62                  0                  2                  0                 0   \n",
       "\n",
       "    LG25_invs_3800000  \n",
       "0                   0  \n",
       "1                   0  \n",
       "2                   0  \n",
       "3                   0  \n",
       "4                   0  \n",
       "..                ...  \n",
       "58                  0  \n",
       "59                  0  \n",
       "60                  0  \n",
       "61                  0  \n",
       "62                  0  \n",
       "\n",
       "[63 rows x 58665 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "growth_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>indv</th>\n",
       "      <th>sex</th>\n",
       "      <th>population</th>\n",
       "      <th>fork_length</th>\n",
       "      <th>age</th>\n",
       "      <th>spot_count</th>\n",
       "      <th>disease</th>\n",
       "      <th>deformity</th>\n",
       "      <th>nostril_count</th>\n",
       "      <th>LG1_dels_50000</th>\n",
       "      <th>...</th>\n",
       "      <th>LG25_ins_3700000</th>\n",
       "      <th>LG25_invs_3700000</th>\n",
       "      <th>LG25_dels_3750000</th>\n",
       "      <th>LG25_dups_3750000</th>\n",
       "      <th>LG25_ins_3750000</th>\n",
       "      <th>LG25_invs_3750000</th>\n",
       "      <th>LG25_dels_3800000</th>\n",
       "      <th>LG25_dups_3800000</th>\n",
       "      <th>LG25_ins_3800000</th>\n",
       "      <th>LG25_invs_3800000</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>27033489</td>\n",
       "      <td>male</td>\n",
       "      <td>2013B12</td>\n",
       "      <td>268.211388</td>\n",
       "      <td>3</td>\n",
       "      <td>53.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>27033489</td>\n",
       "      <td>male</td>\n",
       "      <td>2013B12</td>\n",
       "      <td>162.068598</td>\n",
       "      <td>1</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>261931510</td>\n",
       "      <td>male</td>\n",
       "      <td>2013B10</td>\n",
       "      <td>227.704511</td>\n",
       "      <td>3</td>\n",
       "      <td>24.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>261931510</td>\n",
       "      <td>male</td>\n",
       "      <td>2013B10</td>\n",
       "      <td>139.704581</td>\n",
       "      <td>1</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>262447031</td>\n",
       "      <td>male</td>\n",
       "      <td>2013B10</td>\n",
       "      <td>164.332852</td>\n",
       "      <td>1</td>\n",
       "      <td>58.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>262447031</td>\n",
       "      <td>male</td>\n",
       "      <td>2013B10</td>\n",
       "      <td>258.806908</td>\n",
       "      <td>3</td>\n",
       "      <td>59.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>275378212</td>\n",
       "      <td>male</td>\n",
       "      <td>2013B12</td>\n",
       "      <td>184.529064</td>\n",
       "      <td>1</td>\n",
       "      <td>36.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>275378212</td>\n",
       "      <td>male</td>\n",
       "      <td>2013B12</td>\n",
       "      <td>282.035539</td>\n",
       "      <td>3</td>\n",
       "      <td>38.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>299826357</td>\n",
       "      <td>female</td>\n",
       "      <td>2013B11</td>\n",
       "      <td>260.368211</td>\n",
       "      <td>3</td>\n",
       "      <td>59.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>299826357</td>\n",
       "      <td>female</td>\n",
       "      <td>2013B11</td>\n",
       "      <td>159.883841</td>\n",
       "      <td>1</td>\n",
       "      <td>64.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>322378787</td>\n",
       "      <td>male</td>\n",
       "      <td>2013B10</td>\n",
       "      <td>263.937463</td>\n",
       "      <td>3</td>\n",
       "      <td>40.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>322378787</td>\n",
       "      <td>male</td>\n",
       "      <td>2013B10</td>\n",
       "      <td>177.515974</td>\n",
       "      <td>1</td>\n",
       "      <td>48.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>734562795</td>\n",
       "      <td>male</td>\n",
       "      <td>2013B11</td>\n",
       "      <td>170.854607</td>\n",
       "      <td>1</td>\n",
       "      <td>41.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>734562795</td>\n",
       "      <td>male</td>\n",
       "      <td>2013B11</td>\n",
       "      <td>272.716241</td>\n",
       "      <td>3</td>\n",
       "      <td>40.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>808141137</td>\n",
       "      <td>male</td>\n",
       "      <td>2013B12</td>\n",
       "      <td>268.182385</td>\n",
       "      <td>3</td>\n",
       "      <td>44.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>808141137</td>\n",
       "      <td>male</td>\n",
       "      <td>2013B12</td>\n",
       "      <td>168.217082</td>\n",
       "      <td>1</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>986994303</td>\n",
       "      <td>male</td>\n",
       "      <td>2013B12</td>\n",
       "      <td>250.116536</td>\n",
       "      <td>3</td>\n",
       "      <td>40.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>986994303</td>\n",
       "      <td>male</td>\n",
       "      <td>2013B12</td>\n",
       "      <td>148.071168</td>\n",
       "      <td>1</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>18 rows × 58665 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         indv     sex population  fork_length  age  spot_count  disease  \\\n",
       "0    27033489    male    2013B12   268.211388    3        53.0      2.0   \n",
       "1    27033489    male    2013B12   162.068598    1        54.0      0.0   \n",
       "13  261931510    male    2013B10   227.704511    3        24.0      2.0   \n",
       "14  261931510    male    2013B10   139.704581    1        34.0      0.0   \n",
       "15  262447031    male    2013B10   164.332852    1        58.0      0.0   \n",
       "16  262447031    male    2013B10   258.806908    3        59.0      2.0   \n",
       "17  275378212    male    2013B12   184.529064    1        36.0      0.0   \n",
       "18  275378212    male    2013B12   282.035539    3        38.0      2.0   \n",
       "21  299826357  female    2013B11   260.368211    3        59.0      2.0   \n",
       "22  299826357  female    2013B11   159.883841    1        64.0      0.0   \n",
       "25  322378787    male    2013B10   263.937463    3        40.0      2.0   \n",
       "26  322378787    male    2013B10   177.515974    1        48.0      0.0   \n",
       "45  734562795    male    2013B11   170.854607    1        41.0      0.0   \n",
       "46  734562795    male    2013B11   272.716241    3        40.0      2.0   \n",
       "49  808141137    male    2013B12   268.182385    3        44.0      2.0   \n",
       "50  808141137    male    2013B12   168.217082    1        54.0      0.0   \n",
       "59  986994303    male    2013B12   250.116536    3        40.0      2.0   \n",
       "60  986994303    male    2013B12   148.071168    1        40.0      0.0   \n",
       "\n",
       "    deformity  nostril_count  LG1_dels_50000  ...  LG25_ins_3700000  \\\n",
       "0         0.0            1.0               2  ...                 1   \n",
       "1         0.0            1.0               2  ...                 1   \n",
       "13        0.0            2.0               3  ...                 1   \n",
       "14        0.0            2.0               3  ...                 1   \n",
       "15        0.0            2.0               4  ...                 1   \n",
       "16        0.0            2.0               4  ...                 1   \n",
       "17        0.0            2.0               1  ...                 0   \n",
       "18        0.0            2.0               1  ...                 0   \n",
       "21        0.0            1.0               1  ...                 0   \n",
       "22        0.0            1.0               1  ...                 0   \n",
       "25        0.0            1.0               4  ...                 1   \n",
       "26        0.0            1.0               4  ...                 1   \n",
       "45        0.0            1.0               2  ...                 1   \n",
       "46        0.0            1.0               2  ...                 1   \n",
       "49        0.0            2.0               4  ...                 1   \n",
       "50        0.0            2.0               4  ...                 1   \n",
       "59        0.0            1.0               4  ...                 0   \n",
       "60        0.0            1.0               4  ...                 0   \n",
       "\n",
       "    LG25_invs_3700000  LG25_dels_3750000  LG25_dups_3750000  LG25_ins_3750000  \\\n",
       "0                   0                  2                  0                 0   \n",
       "1                   0                  2                  0                 0   \n",
       "13                  0                  2                  0                 0   \n",
       "14                  0                  2                  0                 0   \n",
       "15                  0                  2                  0                 0   \n",
       "16                  0                  2                  0                 0   \n",
       "17                  0                  2                  0                 0   \n",
       "18                  0                  2                  0                 0   \n",
       "21                  0                  3                  0                 0   \n",
       "22                  0                  3                  0                 0   \n",
       "25                  0                  2                  0                 0   \n",
       "26                  0                  2                  0                 0   \n",
       "45                  0                  3                  0                 0   \n",
       "46                  0                  3                  0                 0   \n",
       "49                  0                  2                  0                 0   \n",
       "50                  0                  2                  0                 0   \n",
       "59                  0                  1                  0                 0   \n",
       "60                  0                  1                  0                 0   \n",
       "\n",
       "    LG25_invs_3750000  LG25_dels_3800000  LG25_dups_3800000  LG25_ins_3800000  \\\n",
       "0                   0                  1                  0                 1   \n",
       "1                   0                  1                  0                 1   \n",
       "13                  0                  1                  0                 0   \n",
       "14                  0                  1                  0                 0   \n",
       "15                  0                  1                  0                 0   \n",
       "16                  0                  1                  0                 0   \n",
       "17                  0                  1                  0                 0   \n",
       "18                  0                  1                  0                 0   \n",
       "21                  0                  0                  0                 1   \n",
       "22                  0                  0                  0                 1   \n",
       "25                  0                  0                  0                 0   \n",
       "26                  0                  0                  0                 0   \n",
       "45                  0                  1                  0                 1   \n",
       "46                  0                  1                  0                 1   \n",
       "49                  0                  1                  0                 0   \n",
       "50                  0                  1                  0                 0   \n",
       "59                  0                  2                  0                 0   \n",
       "60                  0                  2                  0                 0   \n",
       "\n",
       "    LG25_invs_3800000  \n",
       "0                   0  \n",
       "1                   0  \n",
       "13                  0  \n",
       "14                  0  \n",
       "15                  0  \n",
       "16                  0  \n",
       "17                  0  \n",
       "18                  0  \n",
       "21                  0  \n",
       "22                  0  \n",
       "25                  0  \n",
       "26                  0  \n",
       "45                  0  \n",
       "46                  0  \n",
       "49                  0  \n",
       "50                  0  \n",
       "59                  0  \n",
       "60                  0  \n",
       "\n",
       "[18 rows x 58665 columns]"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sex_df=growth_df.loc[(growth_df['sex'] == \"male\") | (growth_df['sex'] == \"female\")]\n",
    "sex_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Split data in year 1 and year 3 data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "growth_y1 = growth_df.loc[(growth_df['age'] == 1)]\n",
    "growth_y3 = growth_df.loc[(growth_df['age'] == 3)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bin into small --> medium --> big"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Year 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-7-500e8c2916d0>:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  small['fork_length']=\"small\"\n",
      "<ipython-input-7-500e8c2916d0>:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  medium['fork_length']=\"medium\"\n",
      "<ipython-input-7-500e8c2916d0>:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  big['fork_length']=\"big\"\n"
     ]
    }
   ],
   "source": [
    "small=growth_y1.loc[(growth_y1['fork_length'] >= min(growth_y1.fork_length)) & (growth_y1['fork_length'] <= growth_y1.fork_length.quantile(0.33))]\n",
    "small['fork_length']=\"small\"\n",
    "small\n",
    "\n",
    "\n",
    "medium=growth_y1.loc[(growth_y1['fork_length'] > growth_y1.fork_length.quantile(0.33)) & (growth_y1['fork_length'] <= growth_y1.fork_length.quantile(0.66))]\n",
    "medium['fork_length']=\"medium\"\n",
    "medium\n",
    "\n",
    "big=growth_y1.loc[growth_y1['fork_length'] > growth_y1.fork_length.quantile(0.66)]\n",
    "big['fork_length']=\"big\"\n",
    "big\n",
    "\n",
    "small_medium=small.append(medium)\n",
    "binned_y1=small_medium.append(big)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Year 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-8-3ebd253edfbf>:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  small['fork_length']=\"small\"\n",
      "<ipython-input-8-3ebd253edfbf>:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  medium['fork_length']=\"medium\"\n",
      "<ipython-input-8-3ebd253edfbf>:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  big['fork_length']=\"big\"\n"
     ]
    }
   ],
   "source": [
    "small=growth_y3.loc[(growth_y3['fork_length'] >= min(growth_y3.fork_length)) & (growth_y3['fork_length'] <= growth_y3.fork_length.quantile(0.33))]\n",
    "small['fork_length']=\"small\"\n",
    "small\n",
    "\n",
    "\n",
    "medium=growth_y3.loc[(growth_y3['fork_length'] > growth_y3.fork_length.quantile(0.33)) & (growth_y3['fork_length'] <= growth_y3.fork_length.quantile(0.66))]\n",
    "medium['fork_length']=\"medium\"\n",
    "medium\n",
    "\n",
    "big=growth_y3.loc[growth_y3['fork_length'] > growth_y3.fork_length.quantile(0.66)]\n",
    "big['fork_length']=\"big\"\n",
    "big\n",
    "\n",
    "small_medium=small.append(medium)\n",
    "binned_y3=small_medium.append(big)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Do relief F feature selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview of target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "big       11\n",
      "small     11\n",
      "medium    10\n",
      "Name: fork_length, dtype: int64\n",
      "big       11\n",
      "small     10\n",
      "medium    10\n",
      "Name: fork_length, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(binned_y1['fork_length'].value_counts())\n",
    "print(binned_y3['fork_length'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 1, ..., 0, 2, 4],\n",
       "       [1, 1, 1, ..., 0, 0, 1],\n",
       "       [1, 1, 1, ..., 1, 2, 2],\n",
       "       ...,\n",
       "       [0, 1, 0, ..., 0, 1, 5],\n",
       "       [0, 1, 0, ..., 0, 1, 3],\n",
       "       [0, 1, 0, ..., 0, 1, 5]], dtype=int64)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y1_relief_top=[]\n",
    "score_list=[]\n",
    "for value in fs1.top_features_[0:500]:\n",
    "    score=fs1.feature_importances_[value]\n",
    "    score_list.append(score)\n",
    "    y1_relief_top.append(reliefdict1[score])\n",
    "\n",
    "\n",
    "\n",
    "# binned_y1=binned_y1.set_index('indv')\n",
    "binned_y1['sex'] = pd.factorize(binned_y1.sex)[0]\n",
    "binned_y1['population'] = pd.factorize(binned_y1.population)[0]\n",
    "X = np.array(binned_y1[y1_relief_top])\n",
    "y = np.array(binned_y1['fork_length'])\n",
    "\n",
    "\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-11-16 16:16:27,920 - pyswarms.discrete.binary - INFO - Optimize for 500 iters with {'c1': 0.1, 'c2': 0.1, 'w': 0.9, 'k': 1, 'p': 1}\n",
      "pyswarms.discrete.binary: 100%|██████████████████████████████████████████████████████████████|500/500, best_cost=0.0406\n",
      "2020-11-16 18:10:35,543 - pyswarms.discrete.binary - INFO - Optimization finished | best cost: 0.04055999999999999, best pos: [0 1 0 1 1 0 0 1 1 1 1 0 0 0 1 1 0 1 1 0 0 1 0 1 1 1 1 1 1 1 1 1 0 0 1 1 1\n",
      " 1 1 1 0 1 1 1 1 0 1 0 1 1 1 0 0 1 0 1 0 0 1 0 1 0 1 1 1 1 1 0 1 0 1 0 0 0\n",
      " 1 1 1 1 1 1 1 1 0 1 1 0 1 1 1 0 1 1 1 1 1 1 1 1 1 1 0 1 1 1 0 0 1 0 1 1 0\n",
      " 0 0 0 1 1 0 1 0 0 1 1 1 0 0 1 0 0 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 0 1 1\n",
      " 0 1 1 1 0 0 0 1 1 0 1 1 1 1 0 0 0 1 0 1 0 1 1 1 1 1 1 0 1 1 1 1 1 0 1 0 0\n",
      " 1 0 1 1 1 1 0 0 1 1 1 1 1 0 1 1 0 1 1 1 1 1 1 0 0 1 1 1 0 0 1 1 0 1 0 0 1\n",
      " 0 1 0 1 1 1 1 1 1 1 1 1 0 0 0 0 0 1 1 1 0 1 1 1 1 1 1 1 0 1 0 1 0 0 1 1 1\n",
      " 1 1 0 1 0 1 0 0 1 0 0 1 1 1 1 1 1 1 1 1 1 0 1 0 1 1 1 0 1 1 1 1 0 0 1 1 1\n",
      " 1 1 0 1 0 1 1 1 1 0 0 1 1 1 0 1 1 0 0 0 1 1 1 0 1 1 0 1 1 0 1 1 0 1 1 1 0\n",
      " 0 1 0 1 1 0 1 0 1 1 1 0 0 1 0 1 1 1 1 1 0 0 1 0 0 0 1 0 0 1 1 1 1 0 0 1 1\n",
      " 0 1 1 1 1 1 1 1 0 1 0 1 1 0 1 1 1 1 1 1 0 0 0 0 0 1 0 1 0 1 0 1 1 1 0 0 0\n",
      " 1 0 0 0 0 1 0 0 1 1 1 1 0 1 1 1 0 1 0 0 1 0 0 1 1 1 1 1 1 1 0 1 1 1 1 0 1\n",
      " 0 0 1 1 1 0 0 1 0 1 1 1 0 1 1 1 1 1 1 1 1 0 1 0 1 1 1 1 1 1 1 1 1 1 1 0 0\n",
      " 0 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 0 0 1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "331\n",
      "Logistic regression 1.0\n"
     ]
    }
   ],
   "source": [
    "# Import modules\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pyswarms as ps\n",
    "from sklearn import linear_model\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.datasets import make_classification\n",
    "# X, y = make_classification(n_samples=100, n_features=15, n_classes=3,\n",
    "#                            n_informative=4, n_redundant=1, n_repeated=2,\n",
    "#                            random_state=1)\n",
    "\n",
    "\n",
    "# Create an instance of the classifier\n",
    "classifier = linear_model.LogisticRegression()\n",
    "\n",
    "# Define objective function\n",
    "def f_per_particle(m, alpha):\n",
    "    \"\"\"Computes for the objective function per particle\n",
    "\n",
    "    Inputs\n",
    "    ------\n",
    "    m : numpy.ndarray\n",
    "        Binary mask that can be obtained from BinaryPSO, will\n",
    "        be used to mask features.\n",
    "    alpha: float (default is 0.5)\n",
    "        Constant weight for trading-off classifier performance\n",
    "        and number of features\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    numpy.ndarray\n",
    "        Computed objective function\n",
    "    \"\"\"\n",
    "    total_features = X.shape[1]\n",
    "    # Get the subset of the features from the binary mask\n",
    "    if np.count_nonzero(m) == 0:\n",
    "        X_subset = X\n",
    "    else:\n",
    "        X_subset = X[:,m==1]\n",
    "    # Perform classification and store performance in P\n",
    "    classifier.fit(X_subset, y)\n",
    "    P = (classifier.predict(X_subset) == y).mean()\n",
    "    # Compute for the objective function\n",
    "    j = (alpha * (1.0 - P)\n",
    "        + (1.0 - alpha) * (1 - (X_subset.shape[1] / total_features)))\n",
    "\n",
    "    return j\n",
    "\n",
    "def f(x, alpha=0.88):\n",
    "    \"\"\"Higher-level method to do classification in the\n",
    "    whole swarm.\n",
    "\n",
    "    Inputs\n",
    "    ------\n",
    "    x: numpy.ndarray of shape (n_particles, dimensions)\n",
    "        The swarm that will perform the search\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    numpy.ndarray of shape (n_particles, )\n",
    "        The computed loss for each particle\n",
    "    \"\"\"\n",
    "    n_particles = x.shape[0]\n",
    "    j = [f_per_particle(x[i], alpha) for i in range(n_particles)]\n",
    "    return np.array(j)\n",
    "\n",
    "# Initialize swarm, arbitrary\n",
    "options = {'c1': 0.1, 'c2': 0.1, 'w':0.9, 'k': 1, 'p':1}\n",
    "\n",
    "# Call instance of PSO\n",
    "dimensions = X.shape[1] # dimensions should be the number of features\n",
    "optimizer = ps.discrete.BinaryPSO(n_particles=500, dimensions=dimensions, options=options)\n",
    "\n",
    "# Perform optimization\n",
    "cost, pos = optimizer.optimize(f, iters=500)\n",
    "\n",
    "iterator=0\n",
    "PSO_list=[]\n",
    "for value in pos:\n",
    "    if value==1:\n",
    "        PSO_list.append(y1_relief_top[iterator])\n",
    "    iterator+=1\n",
    "print(len(PSO_list))\n",
    "\n",
    "x=binned_y1[PSO_list]\n",
    "y = binned_y1.fork_length\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.5,random_state=2)\n",
    "\n",
    "clf = LogisticRegression(random_state=0, max_iter=2000).fit(x_train, y_train)\n",
    "pred = clf.predict(x_test)\n",
    "print(\"Logistic regression\", accuracy_score(y_test, pred))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN 0.5625\n",
      "Naive Bayes 0.4375\n",
      "Logistic regression 1.0\n",
      "Random forest 0.75\n",
      "SVM 1.0\n"
     ]
    }
   ],
   "source": [
    "classifier = KNeighborsClassifier(n_neighbors=5, p=2, metric='minkowski')\n",
    "classifier.fit(x_train, y_train)\n",
    "y_pred = classifier.predict(x_test)\n",
    "print(\"KNN\", accuracy_score(y_test, y_pred))\n",
    "\n",
    "\n",
    "classifier = GaussianNB()\n",
    "classifier.fit(x_train, y_train)\n",
    "y_pred = classifier.predict(x_test)\n",
    "print(\"Naive Bayes\", accuracy_score(y_test, y_pred))\n",
    "\n",
    "clf = LogisticRegression(random_state=0, max_iter=2000).fit(x_train, y_train)\n",
    "pred = clf.predict(x_test)\n",
    "print(\"Logistic regression\", accuracy_score(y_test, pred))\n",
    "\n",
    "ranfor = RandomForestClassifier(n_estimators = 150, criterion = 'entropy', random_state = 5, max_depth = 200)\n",
    "ranfor.fit(x_train, y_train)\n",
    "pred_ranfor = ranfor.predict(x_test)\n",
    "print(\"Random forest\", accuracy_score(y_test, pred_ranfor))\n",
    "pred_ranfor\n",
    "\n",
    "sv = svm.SVC(kernel='linear')\n",
    "sv.fit(x_train, y_train)\n",
    "pred_svm = sv.predict(x_test)\n",
    "print(\"SVM\",accuracy_score(y_test, pred_svm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "291\n"
     ]
    }
   ],
   "source": [
    "iterator=0\n",
    "PSO_list=[]\n",
    "for value in pos:\n",
    "    if value==1:\n",
    "        PSO_list.append(y1_relief_top[iterator])\n",
    "    iterator+=1\n",
    "print(len(PSO_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Classifiers with TuRF Relief-F top 500 features and year 1 data ---\n",
      "\n",
      "KNN 0.5\n",
      "Naive Bayes 0.5\n",
      "Logistic regression 0.875\n",
      "Random forest 0.875\n",
      "SVM 0.9375\n"
     ]
    }
   ],
   "source": [
    "x=binned_y1[PSO_list]\n",
    "y = binned_y1.fork_length\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.5,random_state=2)\n",
    "\n",
    "print(\"--- Classifiers with TuRF Relief-F top\",str(len(y1_relief_top)), \"features and year 1 data ---\\n\")\n",
    "classifier = KNeighborsClassifier(n_neighbors=5, p=2, metric='minkowski')\n",
    "classifier.fit(x_train, y_train)\n",
    "y_pred = classifier.predict(x_test)\n",
    "print(\"KNN\", accuracy_score(y_test, y_pred))\n",
    "\n",
    "\n",
    "classifier = GaussianNB()\n",
    "classifier.fit(x_train, y_train)\n",
    "y_pred = classifier.predict(x_test)\n",
    "print(\"Naive Bayes\", accuracy_score(y_test, y_pred))\n",
    "\n",
    "clf = LogisticRegression(random_state=0, max_iter=2000).fit(x_train, y_train)\n",
    "pred = clf.predict(x_test)\n",
    "print(\"Logistic regression\", accuracy_score(y_test, pred))\n",
    "\n",
    "ranfor = RandomForestClassifier(n_estimators = 150, criterion = 'entropy', random_state = 5, max_depth = 200)\n",
    "ranfor.fit(x_train, y_train)\n",
    "pred_ranfor = ranfor.predict(x_test)\n",
    "print(\"Random forest\", accuracy_score(y_test, pred_ranfor))\n",
    "pred_ranfor\n",
    "\n",
    "sv = svm.SVC(kernel='linear')\n",
    "sv.fit(x_train, y_train)\n",
    "pred_svm = sv.predict(x_test)\n",
    "print(\"SVM\",accuracy_score(y_test, pred_svm))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start with year 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created distance array in 0.621058464050293 seconds.\n",
      "Feature scoring under way ...\n",
      "Completed scoring in 121.38548493385315 seconds.\n",
      "Created distance array in 0.3299574851989746 seconds.\n",
      "Feature scoring under way ...\n",
      "Completed scoring in 61.399550676345825 seconds.\n",
      "Created distance array in 0.1770000457763672 seconds.\n",
      "Feature scoring under way ...\n",
      "Completed scoring in 39.347206354141235 seconds.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from skrebate.turf import TuRF\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "binned_y1['sex'] = pd.factorize(binned_y1.sex)[0]\n",
    "binned_y1['population'] = pd.factorize(binned_y1.population)[0]\n",
    "genetic_data=binned_y1\n",
    "features, labels = genetic_data.drop('fork_length', axis=1).values, genetic_data['fork_length'].values\n",
    "headers = list(genetic_data.drop(\"fork_length\", axis=1))\n",
    "fs1 = TuRF(core_algorithm=\"ReliefF\", n_features_to_select=2, pct=0.5,verbose=True)\n",
    "fs1.fit(features, labels, headers)\n",
    "reliefdict1={}\n",
    "for feature_name, feature_score in zip(genetic_data.drop('fork_length', axis=1).columns, fs1.feature_importances_):\n",
    "    reliefdict1[feature_score]=feature_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get top 25 scores year 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'fs1' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-9757da50b4ec>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0my1_relief_top\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mscore_list\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[1;32mfor\u001b[0m \u001b[0mvalue\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mfs1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtop_features_\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m     \u001b[0mscore\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfs1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfeature_importances_\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[0mscore_list\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscore\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'fs1' is not defined"
     ]
    }
   ],
   "source": [
    "import pylab as pl\n",
    "\n",
    "# print(reliefdict)\n",
    "y1_relief_top=[]\n",
    "score_list=[]\n",
    "for value in fs1.top_features_[0:10]:\n",
    "    score=fs1.feature_importances_[value]\n",
    "    score_list.append(score)\n",
    "    y1_relief_top.append(reliefdict1[score])\n",
    "    \n",
    "# df = pd.DataFrame({'Features':y1_relief_top, 'Scores':score_list})\n",
    "# ax = df.plot.bar(x='Features', y='Scores', rot=90)\n",
    "# pl.suptitle(\"Year 1 top 25 feature scores\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get prediction year 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Classifiers with TuRF Relief-F top 10 features and year 1 data ---\n",
      "\n",
      "KNN 0.875\n",
      "Naive Bayes 1.0\n",
      "Logistic regression 1.0\n",
      "Random forest 0.75\n",
      "SVM 0.6875\n",
      "--- Classifiers with TuRF Relief-F top 50 features and year 1 data ---\n",
      "\n",
      "KNN 0.6875\n",
      "Naive Bayes 0.9375\n",
      "Logistic regression 1.0\n",
      "Random forest 1.0\n",
      "SVM 1.0\n",
      "--- Classifiers with TuRF Relief-F top 100 features and year 1 data ---\n",
      "\n",
      "KNN 0.8125\n",
      "Naive Bayes 0.6875\n",
      "Logistic regression 0.9375\n",
      "Random forest 1.0\n",
      "SVM 1.0\n",
      "--- Classifiers with TuRF Relief-F top 200 features and year 1 data ---\n",
      "\n",
      "KNN 0.8125\n",
      "Naive Bayes 0.5625\n",
      "Logistic regression 1.0\n",
      "Random forest 1.0\n",
      "SVM 1.0\n",
      "--- Classifiers with TuRF Relief-F top 500 features and year 1 data ---\n",
      "\n",
      "KNN 0.625\n",
      "Naive Bayes 0.5\n",
      "Logistic regression 0.9375\n",
      "Random forest 1.0\n",
      "SVM 1.0\n"
     ]
    }
   ],
   "source": [
    "def predict(value):\n",
    "    y1_relief_top=[]\n",
    "    for value in fs1.top_features_[0:value]:\n",
    "        score=fs1.feature_importances_[value]\n",
    "        y1_relief_top.append(reliefdict1[score])\n",
    "\n",
    "    x=binned_y1[y1_relief_top]\n",
    "    y = binned_y1.fork_length\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.5,random_state=2)\n",
    "\n",
    "    print(\"--- Classifiers with TuRF Relief-F top\",str(len(y1_relief_top)), \"features and year 1 data ---\\n\")\n",
    "    classifier = KNeighborsClassifier(n_neighbors=5, p=2, metric='minkowski')\n",
    "    classifier.fit(x_train, y_train)\n",
    "    y_pred = classifier.predict(x_test)\n",
    "    print(\"KNN\", accuracy_score(y_test, y_pred))\n",
    "\n",
    "\n",
    "    classifier = GaussianNB()\n",
    "    classifier.fit(x_train, y_train)\n",
    "    y_pred = classifier.predict(x_test)\n",
    "    print(\"Naive Bayes\", accuracy_score(y_test, y_pred))\n",
    "\n",
    "    clf = LogisticRegression(random_state=0, max_iter=2000).fit(x_train, y_train)\n",
    "    pred = clf.predict(x_test)\n",
    "    print(\"Logistic regression\", accuracy_score(y_test, pred))\n",
    "\n",
    "    ranfor = RandomForestClassifier(n_estimators = 150, criterion = 'entropy', random_state = 5, max_depth = 200)\n",
    "    ranfor.fit(x_train, y_train)\n",
    "    pred_ranfor = ranfor.predict(x_test)\n",
    "    print(\"Random forest\", accuracy_score(y_test, pred_ranfor))\n",
    "    pred_ranfor\n",
    "\n",
    "    sv = svm.SVC(kernel='linear')\n",
    "    sv.fit(x_train, y_train)\n",
    "    pred_svm = sv.predict(x_test)\n",
    "    print(\"SVM\",accuracy_score(y_test, pred_svm))\n",
    "\n",
    "def main():\n",
    "    nofeatures=[10, 50, 100, 200, 500]\n",
    "    for value in nofeatures:\n",
    "        predict(value)\n",
    "main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now do year 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created distance array in 0.743976354598999 seconds.\n",
      "Feature scoring under way ...\n",
      "Completed scoring in 148.7708396911621 seconds.\n",
      "Created distance array in 0.43201136589050293 seconds.\n",
      "Feature scoring under way ...\n",
      "Completed scoring in 74.06866335868835 seconds.\n",
      "Created distance array in 0.23000335693359375 seconds.\n",
      "Feature scoring under way ...\n",
      "Completed scoring in 38.271206855773926 seconds.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from skrebate.turf import TuRF\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "binned_y3['sex'] = pd.factorize(binned_y3.sex)[0]\n",
    "binned_y3['population'] = pd.factorize(binned_y3.population)[0]\n",
    "genetic_data=binned_y3\n",
    "features, labels = genetic_data.drop('fork_length', axis=1).values, genetic_data['fork_length'].values\n",
    "headers = list(genetic_data.drop(\"fork_length\", axis=1))\n",
    "fs3 = TuRF(core_algorithm=\"ReliefF\", n_features_to_select=2, pct=0.5,verbose=True)\n",
    "fs3.fit(features, labels, headers)\n",
    "reliefdict3={}\n",
    "for feature_name, feature_score in zip(genetic_data.drop('fork_length', axis=1).columns, fs3.feature_importances_):\n",
    "    reliefdict3[feature_score]=feature_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get top 25 year 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['LG11_dels_31250000', 'LG3_dels_19750000', 'LG24_ins_10650000', 'LG23_dels_15600000', 'LG10_ins_16750000', 'LG14_dels_8550000', 'LG22_dels_18600000', 'LG14_ins_21900000', 'LG19_ins_9550000', 'LG8_dels_13300000', 'LG14_dels_27150000', 'LG9_dels_11550000', 'LG18_dels_30550000', 'LG7_ins_25200000', 'LG2_dels_14300000', 'LG3_dels_14250000', 'LG19_dups_25750000', 'LG19_ins_17800000', 'LG10_invs_2050000', 'LG6_ins_25050000', 'LG6_ins_25050000', 'LG5_dels_33200000', 'LG15_dels_12800000', 'LG14_dels_21900000', 'LG18_ins_28200000']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0.98, 'Year 3 top 25 feature scores')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pylab as pl\n",
    "\n",
    "# print(reliefdict)\n",
    "y3_relief_top=[]\n",
    "score_list=[]\n",
    "for value in fs3.top_features_[0:25]:\n",
    "    score=fs3.feature_importances_[value]\n",
    "    y3_relief_top.append(reliefdict3[score])\n",
    "    score_list.append(score)\n",
    "    \n",
    "print(y3_relief_top)\n",
    "\n",
    "df = pd.DataFrame({'Features':y3_relief_top, 'Scores':score_list})\n",
    "ax = df.plot.bar(x='Features', y='Scores', rot=90, color=\"red\")\n",
    "pl.suptitle(\"Year 3 top 25 feature scores\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get prediction year 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Classifiers with TuRF Relief-F top 25 features and year 3 data ---\n",
      "\n",
      "KNN 0.5\n",
      "Naive Bayes 0.8125\n",
      "Logistic regression 0.8125\n",
      "Random forest 0.9375\n",
      "SVM 0.8125\n",
      "--- Classifiers with TuRF Relief-F top 50 features and year 3 data ---\n",
      "\n",
      "KNN 0.6875\n",
      "Naive Bayes 0.875\n",
      "Logistic regression 0.875\n",
      "Random forest 0.9375\n",
      "SVM 0.875\n",
      "--- Classifiers with TuRF Relief-F top 100 features and year 3 data ---\n",
      "\n",
      "KNN 0.9375\n",
      "Naive Bayes 0.9375\n",
      "Logistic regression 0.9375\n",
      "Random forest 1.0\n",
      "SVM 1.0\n",
      "--- Classifiers with TuRF Relief-F top 200 features and year 3 data ---\n",
      "\n",
      "KNN 0.9375\n",
      "Naive Bayes 0.875\n",
      "Logistic regression 1.0\n",
      "Random forest 0.9375\n",
      "SVM 1.0\n",
      "--- Classifiers with TuRF Relief-F top 500 features and year 3 data ---\n",
      "\n",
      "KNN 0.9375\n",
      "Naive Bayes 0.6875\n",
      "Logistic regression 1.0\n",
      "Random forest 1.0\n",
      "SVM 1.0\n"
     ]
    }
   ],
   "source": [
    "def pred(value):\n",
    "    y3_relief_top=[]\n",
    "    for value in fs3.top_features_[0:value]:\n",
    "        score=fs3.feature_importances_[value]\n",
    "        y3_relief_top.append(reliefdict3[score])\n",
    "    x=binned_y3[y3_relief_top]\n",
    "    y = binned_y3.fork_length\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.5,random_state=2)\n",
    "\n",
    "    print(\"--- Classifiers with TuRF Relief-F top\",str(len(y3_relief_top)), \"features and year 3 data ---\\n\")\n",
    "    classifier = KNeighborsClassifier(n_neighbors=5, p=2, metric='minkowski')\n",
    "    classifier.fit(x_train, y_train)\n",
    "    y_pred = classifier.predict(x_test)\n",
    "    print(\"KNN\", accuracy_score(y_test, y_pred))\n",
    "\n",
    "    classifier = GaussianNB()\n",
    "    classifier.fit(x_train, y_train)\n",
    "    y_pred = classifier.predict(x_test)\n",
    "    print(\"Naive Bayes\", accuracy_score(y_test, y_pred))\n",
    "\n",
    "    clf = LogisticRegression(random_state=0,max_iter=2000).fit(x_train, y_train)\n",
    "    pred = clf.predict(x_test)\n",
    "    print(\"Logistic regression\", accuracy_score(y_test, pred))\n",
    "\n",
    "    ranfor = RandomForestClassifier(n_estimators = 150, criterion = 'entropy', random_state = 5, max_depth = 200)\n",
    "    ranfor.fit(x_train, y_train)\n",
    "    pred_ranfor = ranfor.predict(x_test)\n",
    "    print(\"Random forest\", accuracy_score(y_test, pred_ranfor))\n",
    "    pred_ranfor\n",
    "\n",
    "    sv = svm.SVC(kernel='linear')\n",
    "    sv.fit(x_train, y_train)\n",
    "    pred_svm = sv.predict(x_test)\n",
    "    print(\"SVM\",accuracy_score(y_test, pred_svm))\n",
    "def main():\n",
    "    nofeatures=[25, 50, 100, 200, 500]\n",
    "    for value in nofeatures:\n",
    "        pred(value)\n",
    "main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Year 1 chi-square feature selection and prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Classifiers with chi-square top 25 features and year 1 data ---\n",
      "\n",
      "KNN 0.5625\n",
      "Naive Bayes 0.8125\n",
      "Logistic regression 0.75\n",
      "Random forest 0.5625\n",
      "SVM 0.75\n"
     ]
    }
   ],
   "source": [
    "binned_y1['sex'] = pd.factorize(binned_y1.sex)[0]\n",
    "binned_y1['population'] = pd.factorize(binned_y1.population)[0]\n",
    "y = binned_y1.fork_length\n",
    "X = binned_y1.drop(columns=[\"fork_length\"])\n",
    "bestfeatures = SelectKBest(score_func=chi2, k=10)\n",
    "bestfeatures\n",
    "fit = bestfeatures.fit(X,y)\n",
    "dfscores = pd.DataFrame(fit.scores_)\n",
    "dfcolumns = pd.DataFrame(X.columns)\n",
    "featureScores = pd.concat([dfcolumns,dfscores],axis=1)\n",
    "featureScores.columns = ['Specs','Score']  \n",
    "varc1=str(featureScores.nlargest(26,'Score'))\n",
    "varc1.split()\n",
    "data_listc1=[]\n",
    "for values in varc1.split():\n",
    "    if \"LG\" in values:\n",
    "        data_listc1.append(values)\n",
    "x=X[data_listc1]\n",
    "y = binned_y1.fork_length\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.5,random_state=2)\n",
    "\n",
    "\n",
    "print(\"--- Classifiers with chi-square top\",str(len(data_listc1)), \"features and year 1 data ---\\n\")\n",
    "classifier = KNeighborsClassifier(n_neighbors=5, p=2, metric='minkowski')\n",
    "classifier.fit(x_train, y_train)\n",
    "y_pred = classifier.predict(x_test)\n",
    "print(\"KNN\", accuracy_score(y_test, y_pred))\n",
    "\n",
    "\n",
    "classifier = GaussianNB()\n",
    "classifier.fit(x_train, y_train)\n",
    "y_pred = classifier.predict(x_test)\n",
    "print(\"Naive Bayes\", accuracy_score(y_test, y_pred))\n",
    "\n",
    "clf = LogisticRegression(random_state=0,max_iter=2000).fit(x_train, y_train)\n",
    "pred = clf.predict(x_test)\n",
    "print(\"Logistic regression\", accuracy_score(y_test, pred))\n",
    "\n",
    "ranfor = RandomForestClassifier(n_estimators = 150, criterion = 'entropy', random_state = 5, max_depth = 200)\n",
    "ranfor.fit(x_train, y_train)\n",
    "pred_ranfor = ranfor.predict(x_test)\n",
    "print(\"Random forest\", accuracy_score(y_test, pred_ranfor))\n",
    "pred_ranfor\n",
    "\n",
    "sv = svm.SVC(kernel='linear')\n",
    "sv.fit(x_train, y_train)\n",
    "pred_svm = sv.predict(x_test)\n",
    "print(\"SVM\",accuracy_score(y_test, pred_svm))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Year 3 chi-square feature selection and prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Classifiers with chi-square top 25 features and year 3 data ---\n",
      "\n",
      "KNN 0.8125\n",
      "Naive Bayes 0.75\n",
      "Logistic regression 0.8125\n",
      "Random forest 0.6875\n",
      "SVM 0.8125\n"
     ]
    }
   ],
   "source": [
    "binned_y3['sex'] = pd.factorize(binned_y3.sex)[0]\n",
    "binned_y3['population'] = pd.factorize(binned_y3.population)[0]\n",
    "y = binned_y3.fork_length\n",
    "X = binned_y3.drop(columns=[\"fork_length\"])\n",
    "bestfeatures = SelectKBest(score_func=chi2, k=10)\n",
    "bestfeatures\n",
    "fit = bestfeatures.fit(X,y)\n",
    "dfscores = pd.DataFrame(fit.scores_)\n",
    "dfcolumns = pd.DataFrame(X.columns)\n",
    "featureScores = pd.concat([dfcolumns,dfscores],axis=1)\n",
    "featureScores.columns = ['Specs','Score']  \n",
    "varc3=str(featureScores.nlargest(26,'Score'))\n",
    "varc3.split()\n",
    "data_listc3=[]\n",
    "for values in varc3.split():\n",
    "    if \"LG\" in values:\n",
    "        data_listc3.append(values)\n",
    "x=X[data_listc3]\n",
    "y = binned_y3.fork_length\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.5,random_state=2)\n",
    "\n",
    "\n",
    "print(\"--- Classifiers with chi-square top\",str(len(data_listc3)), \"features and year 3 data ---\\n\")\n",
    "classifier = KNeighborsClassifier(n_neighbors=5, p=2, metric='minkowski')\n",
    "classifier.fit(x_train, y_train)\n",
    "y_pred = classifier.predict(x_test)\n",
    "print(\"KNN\", accuracy_score(y_test, y_pred))\n",
    "\n",
    "\n",
    "classifier = GaussianNB()\n",
    "classifier.fit(x_train, y_train)\n",
    "y_pred = classifier.predict(x_test)\n",
    "print(\"Naive Bayes\", accuracy_score(y_test, y_pred))\n",
    "\n",
    "clf = LogisticRegression(random_state=0,max_iter=2000).fit(x_train, y_train)\n",
    "pred = clf.predict(x_test)\n",
    "print(\"Logistic regression\", accuracy_score(y_test, pred))\n",
    "\n",
    "ranfor = RandomForestClassifier(n_estimators = 150, criterion = 'entropy', random_state = 5, max_depth = 200)\n",
    "ranfor.fit(x_train, y_train)\n",
    "pred_ranfor = ranfor.predict(x_test)\n",
    "print(\"Random forest\", accuracy_score(y_test, pred_ranfor))\n",
    "pred_ranfor\n",
    "\n",
    "sv = svm.SVC(kernel='linear')\n",
    "sv.fit(x_train, y_train)\n",
    "pred_svm = sv.predict(x_test)\n",
    "print(\"SVM\",accuracy_score(y_test, pred_svm))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mutual information year 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Classifiers with chi-square top 26 features and year 3 data ---\n",
      "\n",
      "KNN 0.4375\n",
      "Naive Bayes 0.625\n",
      "Logistic regression 0.5\n",
      "Random forest 0.6875\n",
      "SVM 0.4375\n"
     ]
    }
   ],
   "source": [
    "binned_y3['sex'] = pd.factorize(binned_y3.sex)[0]\n",
    "binned_y3['population'] = pd.factorize(binned_y3.population)[0]\n",
    "y = binned_y3.fork_length\n",
    "X = binned_y3.drop(columns=[\"fork_length\"])\n",
    "bestfeatures = SelectKBest(score_func=mutual_info_classif, k=10)\n",
    "bestfeatures\n",
    "fit = bestfeatures.fit(X,y)\n",
    "dfscores = pd.DataFrame(fit.scores_)\n",
    "dfcolumns = pd.DataFrame(X.columns)\n",
    "featureScores = pd.concat([dfcolumns,dfscores],axis=1)\n",
    "featureScores.columns = ['Specs','Score']  \n",
    "varm3=str(featureScores.nlargest(26,'Score'))\n",
    "varm3.split()\n",
    "data_listm3=[]\n",
    "for values in varm3.split():\n",
    "    if \"LG\" in values:\n",
    "        data_listm3.append(values)\n",
    "x=X[data_listm3]\n",
    "y = binned_y3.fork_length\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.5,random_state=2)\n",
    "\n",
    "\n",
    "print(\"--- Classifiers with chi-square top\",str(len(data_listm3)), \"features and year 3 data ---\\n\")\n",
    "classifier = KNeighborsClassifier(n_neighbors=5, p=2, metric='minkowski')\n",
    "classifier.fit(x_train, y_train)\n",
    "y_pred = classifier.predict(x_test)\n",
    "print(\"KNN\", accuracy_score(y_test, y_pred))\n",
    "\n",
    "\n",
    "classifier = GaussianNB()\n",
    "classifier.fit(x_train, y_train)\n",
    "y_pred = classifier.predict(x_test)\n",
    "print(\"Naive Bayes\", accuracy_score(y_test, y_pred))\n",
    "\n",
    "clf = LogisticRegression(random_state=0,max_iter=2000).fit(x_train, y_train)\n",
    "pred = clf.predict(x_test)\n",
    "print(\"Logistic regression\", accuracy_score(y_test, pred))\n",
    "\n",
    "ranfor = RandomForestClassifier(n_estimators = 150, criterion = 'entropy', random_state = 5, max_depth = 200)\n",
    "ranfor.fit(x_train, y_train)\n",
    "pred_ranfor = ranfor.predict(x_test)\n",
    "print(\"Random forest\", accuracy_score(y_test, pred_ranfor))\n",
    "pred_ranfor\n",
    "\n",
    "sv = svm.SVC(kernel='linear')\n",
    "sv.fit(x_train, y_train)\n",
    "pred_svm = sv.predict(x_test)\n",
    "print(\"SVM\",accuracy_score(y_test, pred_svm))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mutual information year 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Classifiers with chi-square top 26 features and year 3 data ---\n",
      "\n",
      "KNN 0.5625\n",
      "Naive Bayes 0.5625\n",
      "Logistic regression 0.625\n",
      "Random forest 0.75\n",
      "SVM 0.75\n"
     ]
    }
   ],
   "source": [
    "binned_y1['sex'] = pd.factorize(binned_y1.sex)[0]\n",
    "binned_y1['population'] = pd.factorize(binned_y1.population)[0]\n",
    "y = binned_y3.fork_length\n",
    "X = binned_y3.drop(columns=[\"fork_length\"])\n",
    "bestfeatures = SelectKBest(score_func=mutual_info_classif, k=10)\n",
    "bestfeatures\n",
    "fit = bestfeatures.fit(X,y)\n",
    "dfscores = pd.DataFrame(fit.scores_)\n",
    "dfcolumns = pd.DataFrame(X.columns)\n",
    "featureScores = pd.concat([dfcolumns,dfscores],axis=1)\n",
    "featureScores.columns = ['Specs','Score']  \n",
    "varm1=str(featureScores.nlargest(26,'Score'))\n",
    "varm1.split()\n",
    "data_listm1=[]\n",
    "for values in varm1.split():\n",
    "    if \"LG\" in values:\n",
    "        data_listm1.append(values)\n",
    "x=X[data_listm1]\n",
    "y = binned_y3.fork_length\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.5,random_state=2)\n",
    "\n",
    "\n",
    "print(\"--- Classifiers with chi-square top\",str(len(data_listm1)), \"features and year 3 data ---\\n\")\n",
    "classifier = KNeighborsClassifier(n_neighbors=5, p=2, metric='minkowski')\n",
    "classifier.fit(x_train, y_train)\n",
    "y_pred = classifier.predict(x_test)\n",
    "print(\"KNN\", accuracy_score(y_test, y_pred))\n",
    "\n",
    "\n",
    "classifier = GaussianNB()\n",
    "classifier.fit(x_train, y_train)\n",
    "y_pred = classifier.predict(x_test)\n",
    "print(\"Naive Bayes\", accuracy_score(y_test, y_pred))\n",
    "\n",
    "clf = LogisticRegression(random_state=0,max_iter=2000).fit(x_train, y_train)\n",
    "pred = clf.predict(x_test)\n",
    "print(\"Logistic regression\", accuracy_score(y_test, pred))\n",
    "\n",
    "ranfor = RandomForestClassifier(n_estimators = 150, criterion = 'entropy', random_state = 5, max_depth = 200)\n",
    "ranfor.fit(x_train, y_train)\n",
    "pred_ranfor = ranfor.predict(x_test)\n",
    "print(\"Random forest\", accuracy_score(y_test, pred_ranfor))\n",
    "pred_ranfor\n",
    "\n",
    "sv = svm.SVC(kernel='linear')\n",
    "sv.fit(x_train, y_train)\n",
    "pred_svm = sv.predict(x_test)\n",
    "print(\"SVM\",accuracy_score(y_test, pred_svm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LG5_ins_33600000 data_listc1 data_listc3\n",
      "LG13_ins_17400000 data_listc1 y1_relief_top\n",
      "LG1_ins_12250000 data_listc1 data_listc3\n",
      "LG19_dups_25750000 data_listc1 y3_relief_top\n",
      "LG19_dups_25750000 data_listc1 y1_relief_top\n",
      "LG3_dels_19750000 data_listm1 y3_relief_top\n",
      "LG15_dels_12800000 data_listm1 y3_relief_top\n",
      "LG9_dels_11550000 data_listm3 y3_relief_top\n",
      "LG19_dups_25750000 y1_relief_top y3_relief_top\n"
     ]
    }
   ],
   "source": [
    "combined_list= [data_listc1, data_listc3, data_listm1, data_listm3, y1_relief_top, y3_relief_top]\n",
    "combined_list_names= [\"data_listc1\", \"data_listc3\", \"data_listm1\", \"data_listm3\", \"y1_relief_top\", \"y3_relief_top\"]\n",
    "count_list=[]\n",
    "\n",
    "iterator=0\n",
    "for separate_list in combined_list:\n",
    "    for value in separate_list:\n",
    "        for i in range(len(combined_list)-iterator):\n",
    "            for list_against in combined_list[len(combined_list)-1-i]:\n",
    "                if value in list_against:\n",
    "                    if combined_list_names[iterator] != combined_list_names[len(combined_list)-1-i]:\n",
    "                        print(value, combined_list_names[iterator], combined_list_names[len(combined_list)-1-i] )\n",
    "    iterator+=1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

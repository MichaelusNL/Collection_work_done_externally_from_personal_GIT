{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filter bam files on quality 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q20=/workspace/hramzr/2_Phd_PROJECT/VarCallingWGS/q20\n",
    "bams=$(ls /workspace/hramzr/2_Phd_PROJECT/WGS/IR/*.bam)\n",
    "module load samtools/1.7\n",
    "for bam in $bams\n",
    "do\n",
    "prefix=$(basename $bam | awk -F \"_\" '{print $1}')\n",
    "echo \"samtools view -hb -q 20 $bam -o ${q20}/${prefix}_q20.bam\"\n",
    "done | asub -j qfilter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Index q20 bamfiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "module load samtools/1.7\n",
    "for bam in $(ls /workspace/hramzr/2_Phd_PROJECT/VarCallingWGS/q20/*.bam)\n",
    "do\n",
    "    echo \"samtools index $bam\"\n",
    "done | asub -j index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Parliament2 ensemble caller Docker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download docker for singularity\n",
    "module load singularity/2.6.1\n",
    "# singularity pull docker://sameerdcosta/parliament2\n",
    "bsub \\\n",
    "-J \"pull singularity docker\" \\\n",
    "\"singularity pull --name parliament2.simg docker://dnanexus/parliament2:latest\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make separate directionaries for parliament"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bams=$(ls /workspace/hramzr/2_Phd_PROJECT/VarCallingWGS/q20/*.bam)\n",
    "calldir=/workspace/hramzr/2_Phd_PROJECT/VarCallingWGS/parliament2_calling\n",
    "for bam in $bams\n",
    "do\n",
    "prefix=$(basename $bam | awk -F \"_\" '{print $1}')\n",
    "mkdir ${calldir}/$prefix\n",
    "mkdir ${calldir}/${prefix}/outputs\n",
    "done"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load bam, index and reference files into parliament directionaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH=$(getconf PATH)\n",
    "echo $PATH\n",
    "python -v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bams=$(ls /workspace/hramzr/2_Phd_PROJECT/VarCallingWGS/q20/*967038331*.bam)\n",
    "calldir=/workspace/hramzr/2_Phd_PROJECT/VarCallingWGS/parliament2_calling/\n",
    "ref=/workspace/hramzr/2_Phd_PROJECT/snapper_genome/Chrysophrys_auratus.v.1.0.chromosomes.male.map.fasta \n",
    "fai=${ref}.fai\n",
    "log=/workspace/hramzr/2_Phd_PROJECT/VarCallingWGS/logs\n",
    "for bam in $bams\n",
    "do\n",
    "prefix=$(basename $bam | awk -F \"_\" '{print $1}')\n",
    "bai=$(ls /workspace/hramzr/2_Phd_PROJECT/VarCallingWGS/q20/${prefix}*.bai)\n",
    "# echo $bai\n",
    "# echo $bam\n",
    "# echo $prefix\n",
    "# echo $fai\n",
    "# echo $ref\n",
    "bsub -o ${log}/cp.o -e ${log}/cp.e \\\n",
    "\"cp $bam ${calldir}${prefix}/\"\n",
    "bsub -o ${log}/cp.o -e ${log}/cp.e \\\n",
    "\"cp $bai ${calldir}${prefix}/\"\n",
    "bsub -o ${log}/cp.o -e ${log}/cp.e \\\n",
    "\"cp $ref ${calldir}${prefix}/\"\n",
    "bsub -o ${log}/cp.o -e ${log}/cp.e \\\n",
    "\"cp $fai ${calldir}${prefix}/\"\n",
    "bsub -o ${log}/cp.o -e ${log}/cp.e \\\n",
    "\"cp /workspace/hramzr/2_Phd_PROJECT/VarCallingWGS/parliament2.simg ${calldir}${prefix}/\"\n",
    "done"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run parliament2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "python --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "module load singularity/2.6.1\n",
    "bams=$(ls /workspace/hramzr/2_Phd_PROJECT/VarCallingWGS/q20/*967038331*.bam)\n",
    "wdir=/workspace/hramzr/2_Phd_PROJECT/VarCallingWGS/parliament2_calling/\n",
    "out=/workspace/hramzr/2_Phd_PROJECT/VarCallingWGS/parliament2_out\n",
    "indir=/workspace/hramzr/2_Phd_PROJECT/VarCallingWGS/\n",
    "ref=Chrysophrys_auratus.v.1.0.chromosomes.male.map.fasta\n",
    "fai=Chrysophrys_auratus.v.1.0.chromosomes.male.map.fasta.fai\n",
    "log=/workspace/hramzr/2_Phd_PROJECT/VarCallingWGS/logs/\n",
    "for bam in $bams\n",
    "do\n",
    "prefix=$(basename $bam | awk -F \"_\" '{print $1}')\n",
    "cd ${wdir}${prefix}\n",
    "bsub \\\n",
    "-o ${log}sing.out -e ${log}sing.err -J \"sing\" \\\n",
    "-R \"rusage[mem=64000] span[hosts=1]\" \\\n",
    "\"singularity run -B ${wdir}${prefix}:/home/dnanexus/in,${wdir}${prefix}/outputs:/home/dnanexus/out parliament2.simg \\\n",
    "--bam ${prefix}_q20.bam --bai ${prefix}_q20.bam.bai --fai $fai -r $ref \\\n",
    "    --filter_short_contigs \\\n",
    "    --breakdancer \\\n",
    "    --breakseq \\\n",
    "    --manta \\\n",
    "    --cnvnator \\\n",
    "    --lumpy \\\n",
    "    --delly_deletion \\\n",
    "    --delly_insertion \\\n",
    "    --delly_inversion \\\n",
    "    --delly_duplication \\\n",
    "    --genotype\"\n",
    "done "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run FreeBayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "indvs=$(cat /workspace/hramzr/2_Phd_PROJECT/VarCallingWGS/help_files/indvs)\n",
    "for value in $indvs\n",
    "do\n",
    "mkdir /workspace/hramzr/2_Phd_PROJECT/VarCallingWGS/freebayes/indv_dirs/${value}\n",
    "done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/workspace/hramzr/2_Phd_PROJECT/VarCallingWGS/q20/000475368_q20.bam\n",
      "/workspace/hramzr/2_Phd_PROJECT/VarCallingWGS/q20/008801547_q20.bam\n",
      "/workspace/hramzr/2_Phd_PROJECT/VarCallingWGS/q20/008808514_q20.bam\n",
      "/workspace/hramzr/2_Phd_PROJECT/VarCallingWGS/q20/008813278_q20.bam\n",
      "/workspace/hramzr/2_Phd_PROJECT/VarCallingWGS/q20/008819521_q20.bam\n",
      "/workspace/hramzr/2_Phd_PROJECT/VarCallingWGS/q20/008820870_q20.bam\n",
      "/workspace/hramzr/2_Phd_PROJECT/VarCallingWGS/q20/008821357_q20.bam\n",
      "/workspace/hramzr/2_Phd_PROJECT/VarCallingWGS/q20/008825059_q20.bam\n",
      "/workspace/hramzr/2_Phd_PROJECT/VarCallingWGS/q20/008825377_q20.bam\n",
      "/workspace/hramzr/2_Phd_PROJECT/VarCallingWGS/q20/008828555_q20.bam\n",
      "/workspace/hramzr/2_Phd_PROJECT/VarCallingWGS/q20/008828871_q20.bam\n",
      "/workspace/hramzr/2_Phd_PROJECT/VarCallingWGS/q20/008831557_q20.bam\n",
      "/workspace/hramzr/2_Phd_PROJECT/VarCallingWGS/q20/008831607_q20.bam\n",
      "/workspace/hramzr/2_Phd_PROJECT/VarCallingWGS/q20/008833125_q20.bam\n",
      "/workspace/hramzr/2_Phd_PROJECT/VarCallingWGS/q20/008841043_q20.bam\n",
      "/workspace/hramzr/2_Phd_PROJECT/VarCallingWGS/q20/008843785_q20.bam\n",
      "/workspace/hramzr/2_Phd_PROJECT/VarCallingWGS/q20/009022893_q20.bam\n",
      "/workspace/hramzr/2_Phd_PROJECT/VarCallingWGS/q20/009026369_q20.bam\n",
      "/workspace/hramzr/2_Phd_PROJECT/VarCallingWGS/q20/009042121_q20.bam\n",
      "/workspace/hramzr/2_Phd_PROJECT/VarCallingWGS/q20/012317803_q20.bam\n",
      "/workspace/hramzr/2_Phd_PROJECT/VarCallingWGS/q20/014513579_q20.bam\n",
      "/workspace/hramzr/2_Phd_PROJECT/VarCallingWGS/q20/015275636_q20.bam\n",
      "/workspace/hramzr/2_Phd_PROJECT/VarCallingWGS/q20/027033489_q20.bam\n",
      "/workspace/hramzr/2_Phd_PROJECT/VarCallingWGS/q20/077793299_q20.bam\n",
      "/workspace/hramzr/2_Phd_PROJECT/VarCallingWGS/q20/083800743_q20.bam\n",
      "/workspace/hramzr/2_Phd_PROJECT/VarCallingWGS/q20/090001781_q20.bam\n",
      "/workspace/hramzr/2_Phd_PROJECT/VarCallingWGS/q20/096100681_q20.bam\n",
      "/workspace/hramzr/2_Phd_PROJECT/VarCallingWGS/q20/109947113_q20.bam\n",
      "/workspace/hramzr/2_Phd_PROJECT/VarCallingWGS/q20/140942470_q20.bam\n",
      "/workspace/hramzr/2_Phd_PROJECT/VarCallingWGS/q20/145693354_q20.bam\n",
      "/workspace/hramzr/2_Phd_PROJECT/VarCallingWGS/q20/184889037_q20.bam\n",
      "/workspace/hramzr/2_Phd_PROJECT/VarCallingWGS/q20/197458872_q20.bam\n",
      "/workspace/hramzr/2_Phd_PROJECT/VarCallingWGS/q20/212582674_q20.bam\n",
      "/workspace/hramzr/2_Phd_PROJECT/VarCallingWGS/q20/220020828_q20.bam\n",
      "/workspace/hramzr/2_Phd_PROJECT/VarCallingWGS/q20/225909887_q20.bam\n",
      "/workspace/hramzr/2_Phd_PROJECT/VarCallingWGS/q20/239454473_q20.bam\n",
      "/workspace/hramzr/2_Phd_PROJECT/VarCallingWGS/q20/243417191_q20.bam\n",
      "/workspace/hramzr/2_Phd_PROJECT/VarCallingWGS/q20/261931510_q20.bam\n",
      "/workspace/hramzr/2_Phd_PROJECT/VarCallingWGS/q20/262447031_q20.bam\n",
      "/workspace/hramzr/2_Phd_PROJECT/VarCallingWGS/q20/275378212_q20.bam\n",
      "/workspace/hramzr/2_Phd_PROJECT/VarCallingWGS/q20/279192515_q20.bam\n",
      "/workspace/hramzr/2_Phd_PROJECT/VarCallingWGS/q20/296841509_q20.bam\n",
      "/workspace/hramzr/2_Phd_PROJECT/VarCallingWGS/q20/299826357_q20.bam\n",
      "/workspace/hramzr/2_Phd_PROJECT/VarCallingWGS/q20/301050525_q20.bam\n",
      "/workspace/hramzr/2_Phd_PROJECT/VarCallingWGS/q20/305981370_q20.bam\n",
      "/workspace/hramzr/2_Phd_PROJECT/VarCallingWGS/q20/322378787_q20.bam\n",
      "/workspace/hramzr/2_Phd_PROJECT/VarCallingWGS/q20/358075192_q20.bam\n",
      "/workspace/hramzr/2_Phd_PROJECT/VarCallingWGS/q20/390130722_q20.bam\n",
      "/workspace/hramzr/2_Phd_PROJECT/VarCallingWGS/q20/396985257_q20.bam\n",
      "/workspace/hramzr/2_Phd_PROJECT/VarCallingWGS/q20/397065822_q20.bam\n",
      "/workspace/hramzr/2_Phd_PROJECT/VarCallingWGS/q20/410128477_q20.bam\n",
      "/workspace/hramzr/2_Phd_PROJECT/VarCallingWGS/q20/453817879_q20.bam\n",
      "/workspace/hramzr/2_Phd_PROJECT/VarCallingWGS/q20/477198320_q20.bam\n",
      "/workspace/hramzr/2_Phd_PROJECT/VarCallingWGS/q20/498476286_q20.bam\n",
      "/workspace/hramzr/2_Phd_PROJECT/VarCallingWGS/q20/504243687_q20.bam\n",
      "/workspace/hramzr/2_Phd_PROJECT/VarCallingWGS/q20/520095148_q20.bam\n",
      "/workspace/hramzr/2_Phd_PROJECT/VarCallingWGS/q20/551118489_q20.bam\n",
      "/workspace/hramzr/2_Phd_PROJECT/VarCallingWGS/q20/592865129_q20.bam\n",
      "/workspace/hramzr/2_Phd_PROJECT/VarCallingWGS/q20/600570777_q20.bam\n",
      "/workspace/hramzr/2_Phd_PROJECT/VarCallingWGS/q20/629742264_q20.bam\n",
      "/workspace/hramzr/2_Phd_PROJECT/VarCallingWGS/q20/636039763_q20.bam\n",
      "/workspace/hramzr/2_Phd_PROJECT/VarCallingWGS/q20/650616751_q20.bam\n",
      "/workspace/hramzr/2_Phd_PROJECT/VarCallingWGS/q20/661305928_q20.bam\n",
      "/workspace/hramzr/2_Phd_PROJECT/VarCallingWGS/q20/690179560_q20.bam\n",
      "/workspace/hramzr/2_Phd_PROJECT/VarCallingWGS/q20/734562795_q20.bam\n",
      "/workspace/hramzr/2_Phd_PROJECT/VarCallingWGS/q20/750067070_q20.bam\n",
      "/workspace/hramzr/2_Phd_PROJECT/VarCallingWGS/q20/753129955_q20.bam\n",
      "/workspace/hramzr/2_Phd_PROJECT/VarCallingWGS/q20/764636580_q20.bam\n",
      "/workspace/hramzr/2_Phd_PROJECT/VarCallingWGS/q20/808141137_q20.bam\n",
      "/workspace/hramzr/2_Phd_PROJECT/VarCallingWGS/q20/808177555_q20.bam\n",
      "/workspace/hramzr/2_Phd_PROJECT/VarCallingWGS/q20/817081985_q20.bam\n",
      "/workspace/hramzr/2_Phd_PROJECT/VarCallingWGS/q20/844410657_q20.bam\n",
      "/workspace/hramzr/2_Phd_PROJECT/VarCallingWGS/q20/853067240_q20.bam\n",
      "/workspace/hramzr/2_Phd_PROJECT/VarCallingWGS/q20/859394261_q20.bam\n",
      "/workspace/hramzr/2_Phd_PROJECT/VarCallingWGS/q20/909956485_q20.bam\n",
      "/workspace/hramzr/2_Phd_PROJECT/VarCallingWGS/q20/934689216_q20.bam\n",
      "/workspace/hramzr/2_Phd_PROJECT/VarCallingWGS/q20/967038331_q20.bam\n",
      "/workspace/hramzr/2_Phd_PROJECT/VarCallingWGS/q20/985661182_q20.bam\n",
      "/workspace/hramzr/2_Phd_PROJECT/VarCallingWGS/q20/986994303_q20.bam\n",
      "/workspace/hramzr/2_Phd_PROJECT/VarCallingWGS/q20/998916898_q20.bam\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "module load freebayes/1.1.0\n",
    "module load tabix/0.2.6\n",
    "module load samtools/1.7\n",
    "export TMPDIR=/workspace/hramzr/2_Phd_PROJECT/GBS/vcf_snapper/tmp\n",
    "\n",
    "OUT=\"/workspace/hramzr/2_Phd_PROJECT/VarCallingWGS/freebayes\"\n",
    "LOG=\"${OUT}/logs\"\n",
    "SAMPLES=\"/workspace/hramzr/2_Phd_PROJECT/VarCallingWGS/help_files/male_female_bams.lst\"\n",
    "PAR=\"/software/bioinformatics/freebayes-1.1.0/scripts\"\n",
    "ref=/workspace/hramzr/2_Phd_PROJECT/snapper_genome/Chrysophrys_auratus.v.1.0.chromosomes.male.map.fasta \n",
    "fai=${ref}.fai\n",
    "TEMP=/workspace/hramzr/2_Phd_PROJECT/VarCallingWGS/freebayes/tmp\n",
    "\n",
    "bsub << EOF\n",
    "#!/bin/bash\n",
    "#BSUB -J \"Free\"\n",
    "#BSUB -o ${LOG}/freeb.out \n",
    "#BSUB -e ${LOG}/freeb.err\n",
    "#BSUB -n 80\n",
    "#BSUB -R \"span[hosts=1]\"\n",
    "\n",
    "freebayes-parallel <($PAR/fasta_generate_regions.py $fai 1000000) 80 \\\n",
    "             -f ${ref} \\\n",
    "             -L ${SAMPLES} \\\n",
    "             --ploidy 2 \\\n",
    "             --report-genotype-likelihood-max \\\n",
    "             --min-base-quality 10 \\\n",
    "             --min-mapping-quality 20 \\\n",
    "             --genotype-qualities \\\n",
    "             --use-mapping-quality \\\n",
    "             --no-mnps \\\n",
    "             --no-complex \\\n",
    "             --max-complex-gap 50 \\\n",
    "             --min-alternate-fraction 0.1 \\\n",
    "             --min-repeat-entropy 1 \\\n",
    "             --no-partial-observations \\\n",
    "             --min-coverage 10 \\\n",
    "             --max-coverage 500 \\\n",
    "             --pooled-continuous>${OUT}/male_female_Samples_FB.vcf\n",
    "EOF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job <434345> is submitted to default queue <lowpriority>.\n",
      "Job <434346> is submitted to default queue <lowpriority>.\n",
      "Job <434347> is submitted to default queue <lowpriority>.\n",
      "Job <434348> is submitted to default queue <lowpriority>.\n",
      "Job <434349> is submitted to default queue <lowpriority>.\n",
      "Job <434350> is submitted to default queue <lowpriority>.\n",
      "Job <434351> is submitted to default queue <lowpriority>.\n",
      "Job <434352> is submitted to default queue <lowpriority>.\n",
      "Job <434353> is submitted to default queue <lowpriority>.\n",
      "Job <434354> is submitted to default queue <lowpriority>.\n",
      "Job <434355> is submitted to default queue <lowpriority>.\n",
      "Job <434356> is submitted to default queue <lowpriority>.\n",
      "Job <434357> is submitted to default queue <lowpriority>.\n",
      "Job <434358> is submitted to default queue <lowpriority>.\n",
      "Job <434359> is submitted to default queue <lowpriority>.\n",
      "Job <434360> is submitted to default queue <lowpriority>.\n",
      "Job <434361> is submitted to default queue <lowpriority>.\n",
      "Job <434362> is submitted to default queue <lowpriority>.\n",
      "Job <434363> is submitted to default queue <lowpriority>.\n",
      "Job <434364> is submitted to default queue <lowpriority>.\n",
      "Job <434365> is submitted to default queue <lowpriority>.\n",
      "Job <434366> is submitted to default queue <lowpriority>.\n",
      "Job <434367> is submitted to default queue <lowpriority>.\n",
      "Job <434368> is submitted to default queue <lowpriority>.\n",
      "Job <434369> is submitted to default queue <lowpriority>.\n",
      "Job <434370> is submitted to default queue <lowpriority>.\n",
      "Job <434371> is submitted to default queue <lowpriority>.\n",
      "Job <434372> is submitted to default queue <lowpriority>.\n",
      "Job <434373> is submitted to default queue <lowpriority>.\n",
      "Job <434374> is submitted to default queue <lowpriority>.\n",
      "Job <434375> is submitted to default queue <lowpriority>.\n",
      "Job <434376> is submitted to default queue <lowpriority>.\n",
      "Job <434377> is submitted to default queue <lowpriority>.\n",
      "Job <434378> is submitted to default queue <lowpriority>.\n",
      "Job <434379> is submitted to default queue <lowpriority>.\n",
      "Job <434380> is submitted to default queue <lowpriority>.\n",
      "Job <434381> is submitted to default queue <lowpriority>.\n",
      "Job <434382> is submitted to default queue <lowpriority>.\n",
      "Job <434383> is submitted to default queue <lowpriority>.\n",
      "Job <434384> is submitted to default queue <lowpriority>.\n",
      "Job <434385> is submitted to default queue <lowpriority>.\n",
      "Job <434386> is submitted to default queue <lowpriority>.\n",
      "Job <434387> is submitted to default queue <lowpriority>.\n",
      "Job <434388> is submitted to default queue <lowpriority>.\n",
      "Job <434389> is submitted to default queue <lowpriority>.\n",
      "Job <434390> is submitted to default queue <lowpriority>.\n",
      "Job <434391> is submitted to default queue <lowpriority>.\n",
      "Job <434392> is submitted to default queue <lowpriority>.\n",
      "Job <434393> is submitted to default queue <lowpriority>.\n",
      "Job <434394> is submitted to default queue <lowpriority>.\n",
      "Job <434395> is submitted to default queue <lowpriority>.\n",
      "Job <434396> is submitted to default queue <lowpriority>.\n",
      "Job <434397> is submitted to default queue <lowpriority>.\n",
      "Job <434398> is submitted to default queue <lowpriority>.\n",
      "Job <434399> is submitted to default queue <lowpriority>.\n",
      "Job <434400> is submitted to default queue <lowpriority>.\n",
      "Job <434401> is submitted to default queue <lowpriority>.\n",
      "Job <434402> is submitted to default queue <lowpriority>.\n",
      "Job <434403> is submitted to default queue <lowpriority>.\n",
      "Job <434404> is submitted to default queue <lowpriority>.\n",
      "Job <434405> is submitted to default queue <lowpriority>.\n",
      "Job <434406> is submitted to default queue <lowpriority>.\n",
      "Job <434407> is submitted to default queue <lowpriority>.\n",
      "Job <434408> is submitted to default queue <lowpriority>.\n",
      "Job <434409> is submitted to default queue <lowpriority>.\n",
      "Job <434410> is submitted to default queue <lowpriority>.\n",
      "Job <434411> is submitted to default queue <lowpriority>.\n",
      "Job <434412> is submitted to default queue <lowpriority>.\n",
      "Job <434413> is submitted to default queue <lowpriority>.\n",
      "Job <434414> is submitted to default queue <lowpriority>.\n",
      "Job <434415> is submitted to default queue <lowpriority>.\n",
      "Job <434416> is submitted to default queue <lowpriority>.\n",
      "Job <434417> is submitted to default queue <lowpriority>.\n",
      "Job <434418> is submitted to default queue <lowpriority>.\n",
      "Job <434419> is submitted to default queue <lowpriority>.\n",
      "Job <434420> is submitted to default queue <lowpriority>.\n",
      "Job <434421> is submitted to default queue <lowpriority>.\n",
      "Job <434422> is submitted to default queue <lowpriority>.\n",
      "Job <434423> is submitted to default queue <lowpriority>.\n",
      "Job <434424> is submitted to default queue <lowpriority>.\n"
     ]
    }
   ],
   "source": [
    "module load freebayes/1.1.0\n",
    "module load tabix/0.2.6\n",
    "module load samtools/1.7\n",
    "export TMPDIR=/workspace/hramzr/2_Phd_PROJECT/GBS/vcf_snapper/tmp\n",
    "OUT=\"/workspace/hramzr/2_Phd_PROJECT/VarCallingWGS/freebayes/indv_dirs/\"\n",
    "LOG=\"/workspace/hramzr/2_Phd_PROJECT/VarCallingWGS/freebayes/indv_dirs/logs\"\n",
    "SAMPLES=\"/workspace/hramzr/2_Phd_PROJECT/VarCallingWGS/help_files/male_female_bams.lst\"\n",
    "PAR=\"/software/bioinformatics/freebayes-1.1.0/scripts\"\n",
    "ref=/workspace/hramzr/2_Phd_PROJECT/snapper_genome/Chrysophrys_auratus.v.1.0.chromosomes.male.map.fasta \n",
    "fai=${ref}.fai\n",
    "TEMP=/workspace/hramzr/2_Phd_PROJECT/VarCallingWGS/freebayes/tmp\n",
    "bamlst=$(find /workspace/hramzr/2_Phd_PROJECT/VarCallingWGS/q20/*.bam)\n",
    "for value in $bamlst\n",
    "do\n",
    "prefix=$(echo $value | awk -F '/' '{print $NF}' | awk -F \"_\" '{print $1}')\n",
    "bsub << EOF\n",
    "#!/bin/bash\n",
    "#BSUB -J \"Free\"\n",
    "#BSUB -o ${LOG}/freeb.out \n",
    "#BSUB -e ${LOG}/freeb.err\n",
    "#BSUB -n 4\n",
    "#BSUB -R \"span[hosts=1]\"\n",
    "\n",
    "freebayes-parallel <($PAR/fasta_generate_regions.py $fai 1000000) 80 \\\n",
    "             -f ${ref} ${value} \\\n",
    "             --ploidy 2 \\\n",
    "             --report-genotype-likelihood-max \\\n",
    "             --min-base-quality 10 \\\n",
    "             --min-mapping-quality 20 \\\n",
    "             --genotype-qualities \\\n",
    "             --use-mapping-quality \\\n",
    "             --no-mnps \\\n",
    "             --no-complex \\\n",
    "             --max-complex-gap 50 \\\n",
    "             --min-alternate-fraction 0.1 \\\n",
    "             --min-repeat-entropy 1 \\\n",
    "             --no-partial-observations \\\n",
    "             --min-coverage 10 \\\n",
    "             --max-coverage 500 \\\n",
    "             --pooled-continuous>${OUT}${prefix}/${prefix}_sample_FB.vcf\n",
    "EOF\n",
    "done"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sex trait search\n",
    "### First we need to separate female from male samples and make a selection of an equal number of samples\n",
    "#### Here that is 9 males and 9 females"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sex_list=/powerplant/workspace/hramzr/2_Phd_PROJECT/Genomics/Fish/Resequencing/Chrysophrys_auratus/10565/metadata/additional_metadata/2017_03_06_mb_sex_determination.txt\n",
    "cat $sex_list | tail -n+2 | awk '{print $4, $5}' | egrep \"female\">/workspace/hramzr/2_Phd_PROJECT/VarCallingWGS/help_files/females_sexfile2017.lst\n",
    "cat $sex_list | tail -n+2 | awk '{print $4, $5}' | egrep -w \"male\">/workspace/hramzr/2_Phd_PROJECT/VarCallingWGS/help_files/males_sexfile2017.lst\n",
    "ls /workspace/hramzr/2_Phd_PROJECT/VarCallingWGS/q20/*.bam | awk -F \"/\" '{print $NF}' | awk -F \"_\" '{print $1}'>/workspace/hramzr/2_Phd_PROJECT/VarCallingWGS/help_files/indvs\n",
    "\n",
    "cat /workspace/hramzr/2_Phd_PROJECT/VarCallingWGS/help_files/indvs /workspace/hramzr/2_Phd_PROJECT/VarCallingWGS/help_files/females_sexfile2017.lst | tr -d [a-zA-Z] | tr -d \" \" | sort | uniq -c | sort -rk1 | egrep -w \"2\" | \\\n",
    "awk '{print $2}'>/workspace/hramzr/2_Phd_PROJECT/VarCallingWGS/help_files/females.lst\n",
    "\n",
    "cat /workspace/hramzr/2_Phd_PROJECT/VarCallingWGS/help_files/indvs /workspace/hramzr/2_Phd_PROJECT/VarCallingWGS/help_files/males_sexfile2017.lst | tr -d [a-zA-Z] | tr -d \" \" | sort | uniq -c | sort -rk1 | egrep -w \"2\" | \\\n",
    "awk '{print $2}'>/workspace/hramzr/2_Phd_PROJECT/VarCallingWGS/help_files/males.lst\n",
    "\n",
    "cat /workspace/hramzr/2_Phd_PROJECT/VarCallingWGS/help_files/males.lst | wc -l\n",
    "cat /workspace/hramzr/2_Phd_PROJECT/VarCallingWGS/help_files/females.lst | wc -l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vcf_dir=/workspace/hramzr/2_Phd_PROJECT/VarCallingWGS/parliament2_calling/\n",
    "female_ids=/workspace/hramzr/2_Phd_PROJECT/VarCallingWGS/help_files/females.lst \n",
    "male_ids=/workspace/hramzr/2_Phd_PROJECT/VarCallingWGS/help_files/males.lst"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make number to size plots for inversions/duplications/deletions\n",
    "### Start with making a grouped cat variable to get sizes and N for males and females"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "female_ids=$(cat /workspace/hramzr/2_Phd_PROJECT/VarCallingWGS/help_files/females.lst) \n",
    "male_ids=$(cat /workspace/hramzr/2_Phd_PROJECT/VarCallingWGS/help_files/males.lst) \n",
    "vcf_dir=/workspace/hramzr/2_Phd_PROJECT/VarCallingWGS/parliament2_calling/\n",
    "\n",
    "female_vcfs=\"\"\n",
    "for idf in $female_ids\n",
    "do\n",
    "female_vcfs+=\"/workspace/hramzr/2_Phd_PROJECT/VarCallingWGS/parliament2_calling/${idf}/outputs/${idf}_q20.survivor_sorted.vcf \"\n",
    "done\n",
    "\n",
    "male_vcfs=\"\"\n",
    "for idm in $male_ids\n",
    "do\n",
    "male_vcfs+=\"/workspace/hramzr/2_Phd_PROJECT/VarCallingWGS/parliament2_calling/${idm}/outputs/${idm}_q20.survivor_sorted.vcf \"\n",
    "done"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Then call the amount of DEL DUP INS INV TRA for all of the female samples and male samples\n",
    "#### Output is file with N and Size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out=/workspace/hramzr/2_Phd_PROJECT/VarCallingWGS/help_files/\n",
    "#GET DELS\n",
    "cat $female_vcfs | egrep -v \"#\" | \\\n",
    "tr \";\" \" \" | awk '{if (substr($3,1,3)==\"DEL\"){print substr($10,8)}}' | sort | uniq -c | sed -e 's/^[[:space:]]*//'>${out}female_dels.file\n",
    "\n",
    "cat $male_vcfs | egrep -v \"#\" | \\\n",
    "tr \";\" \" \" | awk '{if (substr($3,1,3)==\"DEL\"){print substr($10,8)}}' | sort | uniq -c | sed -e 's/^[[:space:]]*//'>${out}male_dels.file\n",
    "#GET DUPS\n",
    "cat $female_vcfs | egrep -v \"#\" | \\\n",
    "tr \";\" \" \" | awk '{if (substr($3,1,3)==\"DUP\"){print substr($10,8)}}' | sort | uniq -c | sed -e 's/^[[:space:]]*//'>${out}female_dups.file\n",
    "\n",
    "cat $male_vcfs | egrep -v \"#\" | \\\n",
    "tr \";\" \" \" | awk '{if (substr($3,1,3)==\"DUP\"){print substr($10,8)}}' | sort | uniq -c | sed -e 's/^[[:space:]]*//'>${out}male_dups.file\n",
    "#GET INS\n",
    "cat $female_vcfs | egrep -v \"#\" | \\\n",
    "tr \";\" \" \" | awk '{if (substr($3,1,3)==\"INS\"){print substr($10,8)}}' | sort | uniq -c | sed -e 's/^[[:space:]]*//'>${out}female_ins.file\n",
    "\n",
    "cat $male_vcfs | egrep -v \"#\" | \\\n",
    "tr \";\" \" \" | awk '{if (substr($3,1,3)==\"INS\"){print substr($10,8)}}' | sort | uniq -c | sed -e 's/^[[:space:]]*//'>${out}male_ins.file\n",
    "\n",
    "#GET INVS\n",
    "cat $female_vcfs | egrep -v \"#\" | \\\n",
    "tr \";\" \" \" | awk '{if (substr($3,1,3)==\"INV\"){print substr($10,8)}}' | sort | uniq -c | sed -e 's/^[[:space:]]*//'>${out}female_invs.file\n",
    "\n",
    "cat $male_vcfs | egrep -v \"#\" | \\\n",
    "tr \";\" \" \" | awk '{if (substr($3,1,3)==\"INV\"){print substr($10,8)}}' | sort | uniq -c | sed -e 's/^[[:space:]]*//'>${out}male_invs.file\n",
    "\n",
    "#GET TRA's\n",
    "cat $female_vcfs | egrep -v \"#\" | \\\n",
    "tr \";\" \" \" | awk '{if (substr($3,1,3)==\"TRA\"){print substr($10,8)}}' | sort | uniq -c | sed -e 's/^[[:space:]]*//'>${out}female_tras.file\n",
    "\n",
    "cat $male_vcfs | egrep -v \"#\" | \\\n",
    "tr \";\" \" \" | awk '{if (substr($3,1,3)==\"TRA\"){print substr($10,8)}}' | sort | uniq -c | sed -e 's/^[[:space:]]*//'>${out}male_tras.file\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot with pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.patches as mpatches\n",
    "\n",
    "basedir='/workspace/hramzr/2_Phd_PROJECT/VarCallingWGS/help_files/'\n",
    "df2=pd.read_csv(basedir+\"male_dels.file\", header=None, delimiter=\" \")  \n",
    "df=pd.read_csv(basedir+\"female_dels.file\", header=None, delimiter=\" \")  \n",
    "ax1 = df.plot(kind='hist',x=0,y=1,figsize=(20,5), bins=500) # scatter plot\n",
    "ax2 = df2.plot(kind='hist',x=0,y=1, figsize=(20,5), ax=ax1, color='r', bins=500, alpha=0.5)\n",
    "tt = mpatches.Patch(color='red', label='females')\n",
    "ch = mpatches.Patch(color='blue', label='males')\n",
    "plt.legend(handles=[tt,ch], loc=0)\n",
    "ax1.set_ylabel(\"Size\")\n",
    "ax1.set_xlabel(\"N\")\n",
    "plt.yscale('log')\n",
    "ax1.set_title(\"Histogram deletions male vs female with bin=500\")\n",
    "plt.show()\n",
    "print (ax1==ax2)\n",
    "\n",
    "\n",
    "\n",
    "basedir='/workspace/hramzr/2_Phd_PROJECT/VarCallingWGS/help_files/'\n",
    "df2=pd.read_csv(basedir+\"male_dups.file\", header=None, delimiter=\" \")  \n",
    "df=pd.read_csv(basedir+\"female_dups.file\", header=None, delimiter=\" \")  \n",
    "ax1 = df.plot(kind='hist',x=0,y=1,figsize=(20,5), bins=500) # scatter plot\n",
    "ax2 = df2.plot(kind='hist',x=0,y=1, figsize=(20,5), ax=ax1, color='r', bins=500, alpha=0.5)\n",
    "tt = mpatches.Patch(color='red', label='females')\n",
    "ch = mpatches.Patch(color='blue', label='males')\n",
    "plt.legend(handles=[tt,ch], loc=0)\n",
    "ax1.set_ylabel(\"Size\")\n",
    "ax1.set_xlabel(\"N\")\n",
    "plt.yscale('log')\n",
    "ax1.set_title(\"Histogram dups male vs female with bin=500\")\n",
    "plt.show()\n",
    "print (ax1==ax2)\n",
    "\n",
    "\n",
    "basedir='/workspace/hramzr/2_Phd_PROJECT/VarCallingWGS/help_files/'\n",
    "df2=pd.read_csv(basedir+\"male_ins.file\", header=None, delimiter=\" \")  \n",
    "df=pd.read_csv(basedir+\"female_ins.file\", header=None, delimiter=\" \")  \n",
    "ax1 = df.plot(kind='hist',x=0,y=1,figsize=(20,5), bins=500) # scatter plot\n",
    "ax2 = df2.plot(kind='hist',x=0,y=1, figsize=(20,5), ax=ax1, color='r', bins=500, alpha=0.5)\n",
    "tt = mpatches.Patch(color='red', label='females')\n",
    "ch = mpatches.Patch(color='blue', label='males')\n",
    "plt.legend(handles=[tt,ch], loc=0)\n",
    "ax1.set_ylabel(\"Size\")\n",
    "ax1.set_xlabel(\"N\")\n",
    "plt.yscale('log')\n",
    "ax1.set_title(\"Histogram ins male vs female with bin=500\")\n",
    "plt.show()\n",
    "print (ax1==ax2)\n",
    "\n",
    "\n",
    "\n",
    "basedir='/workspace/hramzr/2_Phd_PROJECT/VarCallingWGS/help_files/'\n",
    "df2=pd.read_csv(basedir+\"male_invs.file\", header=None, delimiter=\" \")  \n",
    "df2\n",
    "df=pd.read_csv(basedir+\"female_invs.file\", header=None, delimiter=\" \")  \n",
    "ax1 = df.plot(kind='hist',x=0,y=1,figsize=(20,5), bins=500) # scatter plot\n",
    "ax2 = df2.plot(kind='hist',x=0,y=1, figsize=(20,5), ax=ax1, color='r', bins=500, alpha=0.5)\n",
    "tt = mpatches.Patch(color='red', label='females')\n",
    "ch = mpatches.Patch(color='blue', label='males')\n",
    "plt.legend(handles=[tt,ch], loc=0)\n",
    "ax1.set_ylabel(\"Size\")\n",
    "ax1.set_xlabel(\"N\")\n",
    "plt.yscale('log')\n",
    "ax1.set_title(\"Histogram invs male vs female with bin=500\")\n",
    "plt.show()\n",
    "print (ax1==ax2)\n",
    "\n",
    "\n",
    "basedir='/workspace/hramzr/2_Phd_PROJECT/VarCallingWGS/help_files/'\n",
    "df2=pd.read_csv(basedir+\"male_tras.file\", header=None, delimiter=\" \")  \n",
    "df2\n",
    "# df2\n",
    "df=pd.read_csv(basedir+\"female_tras.file\", header=None, delimiter=\" \")  \n",
    "# df\n",
    "ax1 = df.plot(kind='hist',x=0,y=1,figsize=(20,5), bins=10) # scatter plot\n",
    "ax2 = df2.plot(kind='hist',x=0,y=1, figsize=(20,5), ax=ax1, color='r', bins=10, alpha=0.5)\n",
    "tt = mpatches.Patch(color='red', label='females')\n",
    "ch = mpatches.Patch(color='blue', label='males')\n",
    "plt.legend(handles=[tt,ch], loc=0)\n",
    "ax1.set_ylabel(\"Size\")\n",
    "ax1.set_xlabel(\"N\")\n",
    "# plt.yscale('log')\n",
    "ax1.set_title(\"Histogram tras male vs female with bin=500\")\n",
    "plt.show()\n",
    "print (ax1==ax2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis:\n",
    "#### There are no distinct TRAS.\n",
    "#### There are some small distinct male and female numbers and sizes in invs, dups and dels. \n",
    "#### There are clear distinct male and female numbers and sizes in ins. Worth to look more into.\n",
    "## Next up: merge the variants in a unified VCF \n",
    "#### Only tool that can do this isnstead of vcf-merge is SURVIVOR https://github.com/fritzsedlazeck/SURVIVOR\n",
    "#### This is due to the fact that breakpoints are estimates and thus are slightly different between samples even if they are the same variant. Merge-vcf does not account for this due to it being geared toward SNP calling.\n",
    "#### We deal with this by a distance setting specifying the maximal difference between pairs of breakpoints (start1 vs start2 and end1 vs end2)\n",
    "## Start: download the tool from GIT into VCFdir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cd /workspace/hramzr/2_Phd_PROJECT/VarCallingWGS/vcfmerge\n",
    "git clone https://github.com/fritzsedlazeck/SURVIVOR.git\n",
    "cd /workspace/hramzr/2_Phd_PROJECT/VarCallingWGS/vcfmerge/SURVIVOR/Debug\n",
    "make"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load and look at options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "/workspace/hramzr/2_Phd_PROJECT/VarCallingWGS/vcfmerge/SURVIVOR/Debug/SURVIVOR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create list to merge == the 9 males and 9 females"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out=/workspace/hramzr/2_Phd_PROJECT/VarCallingWGS/help_files/\n",
    "rm ${out}mergelist\n",
    "echo $male_vcfs | tr \" \" \"\\n\">${out}mergelist\n",
    "echo $female_vcfs | tr \" \" \"\\n\">>${out}mergelist\n",
    "cat ${out}mergelist\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "female_ids=$(cat /workspace/hramzr/2_Phd_PROJECT/VarCallingWGS/help_files/females.lst) \n",
    "male_ids=$(cat /workspace/hramzr/2_Phd_PROJECT/VarCallingWGS/help_files/males.lst) \n",
    "vcf_dir=/workspace/hramzr/2_Phd_PROJECT/VarCallingWGS/parliament2_calling/\n",
    "female_vcfs=\"\"\n",
    "for idf in $female_ids\n",
    "do\n",
    "female_vcfs+=\"/workspace/hramzr/2_Phd_PROJECT/VarCallingWGS/parliament2_calling/${idf}/outputs/${idf}_q20.combined.genotyped.vcf \"\n",
    "done\n",
    "\n",
    "male_vcfs=\"\"\n",
    "for idm in $male_ids\n",
    "do\n",
    "male_vcfs+=\"/workspace/hramzr/2_Phd_PROJECT/VarCallingWGS/parliament2_calling/${idm}/outputs/${idm}_q20.combined.genotyped.vcf \"\n",
    "done"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merge the files\n",
    "## params = 2 callers, strand, type and 30 bp minimum size with distance breakpointpair being 500 max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out=/workspace/hramzr/2_Phd_PROJECT/VarCallingWGS/help_files/\n",
    "\n",
    "outfile=/workspace/hramzr/2_Phd_PROJECT/VarCallingWGS/vcfmerge/9_male_female_merged_samples.vcf\n",
    "log=//workspace/hramzr/2_Phd_PROJECT/VarCallingWGS/vcfmerge/logs/\n",
    "bsub \\\n",
    "-o ${log}survivor_merge.o -e ${log}survivor_merge.e  -J \"survivor merge\" \\\n",
    "\"/workspace/hramzr/2_Phd_PROJECT/VarCallingWGS/vcfmerge/SURVIVOR/Debug/SURVIVOR merge ${out}mergelist \\\n",
    "5000 1 1 1 0 5 \\\n",
    "${outfile}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create genotype input for statistical parsing\n",
    "## Done with VCFR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get genotype from VCF per sample and scaffold pos\n",
    "library(vcfR)\n",
    "vcf <- read.vcfR(\"/workspace/hramzr/2_Phd_PROJECT/VarCallingWGS/vcfmerge/id_adjusted.vcf\", checkFile=F)\n",
    "gt <- extract.gt(vcf, element = c('GT'))\n",
    "\n",
    "#Extract the genotype and transform it into a table, then write out the results to a csv.\n",
    "?extract.gt\n",
    "library(dplyr)\n",
    "library(data.table)\n",
    "write.csv(gt, \"/workspace/hramzr/2_Phd_PROJECT/VarCallingWGS/vcfmerge/9_male_female_merged_genotypes.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Open with pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df=pd.read_csv(\"/workspace/hramzr/2_Phd_PROJECT/VarCallingWGS/vcfmerge/80_samples.gt.GT.FORMAT\", delimiter=\"\\t\")  \n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "with open(r\"/workspace/hramzr/2_Phd_PROJECT/VarCallingWGS/vcfmerge/9fm_samples.gt.GT.FORMAT\") as f:\n",
    "    next(f)\n",
    "    for line in f:\n",
    "        males=line.split()[2:11]\n",
    "        females=line.split()[11:]\n",
    "        good=\"yes\"\n",
    "        for value in males:\n",
    "            if value in females:\n",
    "                good=\"no\"\n",
    "        if good == \"yes\":\n",
    "            print (line)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indvs = open(r\"/workspace/hramzr/2_Phd_PROJECT/VarCallingWGS/help_files/malesnfemales\", \"r\")\n",
    "indvlist=[]\n",
    "for indv in indvs:\n",
    "    indvlist.append(indv.strip())\n",
    "males=indvlist[0:9]\n",
    "females=indvlist[9:]\n",
    "indexes_m=[]\n",
    "indexes_f=[]\n",
    "with open(r\"/workspace/hramzr/2_Phd_PROJECT/VarCallingWGS/freebayes/male_female_Samples_FB.vcf\") as f:\n",
    "    for line in f:\n",
    "        if \"SID\" in line:\n",
    "            for i in range (18):\n",
    "                if  line.split()[i+9].replace(\"SID_\", \"\") in males:\n",
    "                    indexes_m.append(i+9)\n",
    "                else:\n",
    "                    indexes_f.append(i+9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(indexes_f)\n",
    "print(indexes_m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import collections\n",
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "import collections\n",
    "# chidata = open(\"/workspace/hramzr/2_Phd_PROJECT/VarCallingWGS/help_files/chidata\", \"w\")    \n",
    "# with open(r\"/workspace/hramzr/2_Phd_PROJECT/VarCallingWGS/vcfmerge/9_male_female_merged_samples.vcf\") as f:\n",
    "with open(r\"/workspace/hramzr/2_Phd_PROJECT/VarCallingWGS/freebayes/male_female_Samples_FB.vcf\") as f:\n",
    "    for line in f:\n",
    "        if \"#\" not in line:\n",
    "            end=line.split()[7].split(\";\")[6][4:]\n",
    "            chrom=line.split()[0]\n",
    "            start=line.split()[1]\n",
    "    #         svlen=line.split(\";\")[2][6:]\n",
    "    #         svtype=line.split()[4][1:4]\n",
    "            males=line.split()[indexes_m[0]][0:3], line.split()[indexes_m[1]][0:3],line.split()[indexes_m[2]][0:3],line.split()[indexes_m[3]][0:3],line.split()[indexes_m[4]][0:3], \\\n",
    "            line.split()[indexes_m[5]][0:3], line.split()[indexes_m[6]][0:3], line.split()[indexes_m[7]][0:3], line.split()[indexes_m[8]][0:3]\n",
    "            females=line.split()[indexes_f[0]][0:3], line.split()[indexes_f[1]][0:3], line.split()[indexes_f[2]][0:3], line.split()[indexes_f[3]][0:3], line.split()[indexes_f[4]][0:3], line.split()[indexes_f[5]][0:3], line.split()[indexes_f[6]][0:3], line.split()[indexes_f[7]][0:3], line.split()[indexes_f[8]][0:3]\n",
    "            good=\"yes\"\n",
    "            for value in males:\n",
    "                if value in females:\n",
    "                    good=\"no\"\n",
    "            if good == \"yes\":\n",
    "                if \"0\" not in males or females:\n",
    "                    print (chrom, start, end)\n",
    "                    print(males, females)\n",
    "\n",
    "\n",
    "#             line=list(males)+list(females)\n",
    "#             list_of_unique_indexes=[]\n",
    "#             s = pd.Series(line)\n",
    "#             s = pd.factorize(s)[0] + 1\n",
    "#             final_line = s.tolist()\n",
    "#             list_of_unique_indexes.append(final_line)        \n",
    "#             for line in list_of_unique_indexes:    \n",
    "#                 male = line[0:9]\n",
    "#                 female = line[9:]\n",
    "#                 varlist= []\n",
    "#                 counterM=collections.Counter(male)\n",
    "#                 counterF=collections.Counter(female)\n",
    "#                 for i in range(max(line)):\n",
    "#                     varlist.append([counterM[i+1], counterF[i+1]])\n",
    "#                 if len(counterM)== 1 and len(counterF) == 1:\n",
    "#                     if counterM.keys() != counterF.keys():\n",
    "#                         print (chrom, start)\n",
    "#                         print(males, females)\n",
    "                \n",
    "#                 table = np.array(varlist)\n",
    "\n",
    "#                 chi2_stat, p_val, dof, ex = stats.chi2_contingency(table)   \n",
    "#                 if p_val <0.003:\n",
    "#                     print(males, females)\n",
    "#                     print(str(chrom)+\" \"+str(svtype)+\" \"+str(start)+\" \"+str(end)+\" \"+str(p_val))\n",
    "\n",
    "#             #p_value 1.0 means no difference between samples lower than 1.0 means a difference the lower the more difference\n",
    "\n",
    "#             #write scaffold name, pos and p_value to chi_data out \n",
    "#                 chidata.write(str(chrom)+\" \"+str(svtype)+\" \"+str(start)+\" \"+str(end)+\" \"+str(p_val)+\"\\n\")\n",
    "# chidata.close()   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var=$(cat /workspace/hramzr/2_Phd_PROJECT/VarCallingWGS/help_files/mergelist | awk -F \"/\" '{print $7}')\n",
    "out=/workspace/hramzr/2_Phd_PROJECT/VarCallingWGS/help_files/male_female_bams.lst\n",
    "rm $out\n",
    "for id in $var\n",
    "do\n",
    "find /workspace/hramzr/2_Phd_PROJECT/VarCallingWGS/q20/ | egrep $id | egrep \"*.bam$\">>$out\n",
    "done\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "module load samtools/1.9\n",
    "bsub \\\n",
    "-e /workspace/hramzr/2_Phd_PROJECT/VarCallingWGS/help_files/depth.e -o /workspace/hramzr/2_Phd_PROJECT/VarCallingWGS/help_files/depth.o -J \"depth\" \\\n",
    "\"samtools depth -a -f /workspace/hramzr/2_Phd_PROJECT/VarCallingWGS/help_files/male_female_bams.lst \\\n",
    " -r LG13:17985500-17987800>/workspace/hramzr/2_Phd_PROJECT/VarCallingWGS/help_files/009022893_depth_dels\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import collections\n",
    "import re\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "indvs = open(r\"/workspace/hramzr/2_Phd_PROJECT/VarCallingWGS/help_files/malesnfemales\", \"r\")\n",
    "indvlist=[]\n",
    "for indv in indvs:\n",
    "    indvlist.append(indv.strip())\n",
    "males=indvlist[0:9]\n",
    "females=indvlist[9:]\n",
    "females.append(\"000475368\")\n",
    "\n",
    "\n",
    "\n",
    "indvs = open(r\"/workspace/hramzr/2_Phd_PROJECT/VarCallingWGS/help_files/indvs\", \"r\")\n",
    "body = open(\"/workspace/hramzr/2_Phd_PROJECT/VarCallingWGS/vcfmerge/body\", \"w\")\n",
    "\n",
    "sex=\"\"\n",
    "for indv in indvs:\n",
    "\n",
    "    if str(indv).strip() in males:\n",
    "        sex=\"male\"\n",
    "    elif str(indv).strip() in females:\n",
    "        sex=\"female\"\n",
    "    else:\n",
    "        sex=\"unknown\"        \n",
    "    body.write(indv.strip()+\" \"+sex+\" \")\n",
    "    bin_size=1\n",
    "    chrom=\"LG1\"\n",
    "    with open(r\"/workspace/hramzr/2_Phd_PROJECT/VarCallingWGS/parliament2_calling/\"+ \\\n",
    "               str(indv.split()[0])+\"/outputs/\"+str(indv.split()[0])+\"_q20.combined.genotyped.vcf\", \"r\") as f:\n",
    "        chrom_dict={}\n",
    "        header_list=[]\n",
    "        for i in range(25):\n",
    "            chrom_dict[\"LG\"+str(i+1)]={'DEL':0, 'DUP':0, 'INS':0, 'INV':0, 'TRA':0, 'BND':0}\n",
    "        for line in f:\n",
    "            if \"#\" not in line:\n",
    "#                 if int(start) and int(end\n",
    "                start=line.split()[1]\n",
    "                if chrom != line.split()[0][3:]:\n",
    "                    bin_size=1\n",
    "                if ((int(start)/1000000)>bin_size):\n",
    "#                     print(start)                    \n",
    "                    row=str(chrom_dict[chrom])\n",
    "                    row=re.sub(\"[^0-9]\", \" \", row)\n",
    "                    row=' '.join(row.split())\n",
    "#                     print(chrom)\n",
    "\n",
    "                    body.write(row+\" \")\n",
    "                   \n",
    "                    for i in range(25):\n",
    "                        chrom_dict[\"LG\"+str(i+1)]={'DEL':0, 'DUP':0, 'INS':0, 'INV':0, 'TRA':0, 'BND':0}\n",
    "                    bin_size+=1\n",
    "                end=line.split()[7].split(\";\")[6][4:]\n",
    "                chrom=line.split()[0][3:]\n",
    "                start=line.split()[1]\n",
    "                svlen=line.split(\";\")[2][7:]\n",
    "                svtype=line.split(\";\")[3][7:]\n",
    "                chrom_dict[chrom][svtype]+=1\n",
    "    \n",
    "    body.write(\"\\n\")\n",
    "body.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import collections\n",
    "import re\n",
    "\n",
    "# indvs = open(r\"/workspace/hramzr/2_Phd_PROJECT/VarCallingWGS/help_files/indvs\", \"r\")\n",
    "\n",
    "\n",
    "# for indv in indvs:\n",
    "#     bin_size=1\n",
    "#     chrom=\"LG1\"\n",
    "#     with open(r\"/workspace/hramzr/2_Phd_PROJECT/VarCallingWGS/parliament2_calling/\"+ \\\n",
    "#                str(indv.split()[0])+\"/outputs/\"+str(indv.split()[0])+\"_q20.combined.genotyped.vcf\", \"r\") as f:\n",
    "#         chrom_dict={}\n",
    "#         header_list=[]\n",
    "#         for i in range(25):\n",
    "#             chrom_dict[\"LG\"+str(i+1)]={'DEL':0, 'DUP':0, 'INS':0, 'INV':0, 'TRA':0, 'BND':0}\n",
    "#             header_list.append(\"LG\"+str(i+1)+\" DEL\", \"LG\"+str(i+1)+\" DUP\")\n",
    "#         for line in f:\n",
    "#             if \"#\" not in line:\n",
    "# #                 if int(start) and int(end\n",
    "#                 start=line.split()[1]\n",
    "#                 if chrom != line.split()[0][3:]:\n",
    "#                     bin_size=1\n",
    "#                 if ((int(start)/1000000)>bin_size):\n",
    "#                     print(start)                    \n",
    "#                     row=str(chrom_dict[chrom])\n",
    "#                     row=re.sub(\"[^0-9]\", \" \", row)\n",
    "#                     row=' '.join(row.split())\n",
    "#                     print(chrom)\n",
    "\n",
    "#                     print(row+\"\\n\")\n",
    "                   \n",
    "#                     for i in range(25):\n",
    "#                         chrom_dict[\"LG\"+str(i+1)]={'DEL':0, 'DUP':0, 'INS':0, 'INV':0, 'TRA':0, 'BND':0}\n",
    "#                     bin_size+=1\n",
    "#                 end=line.split()[7].split(\";\")[6][4:]\n",
    "#                 chrom=line.split()[0][3:]\n",
    "#                 start=line.split()[1]\n",
    "#                 svlen=line.split(\";\")[2][7:]\n",
    "#                 svtype=line.split(\";\")[3][7:]\n",
    "#                 chrom_dict[chrom][svtype]+=1\n",
    "#     break\n",
    "\n",
    "                    \n",
    "\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "indvs = open(r\"/workspace/hramzr/2_Phd_PROJECT/VarCallingWGS/help_files/indvs\", \"r\")\n",
    "headers = open(\"/workspace/hramzr/2_Phd_PROJECT/VarCallingWGS/vcfmerge/headers\", \"w\")\n",
    "\n",
    "for indv in indvs:\n",
    "    bin_size=1\n",
    "    chrom=\"LG1\"\n",
    "    headers.write(\"indv sex \")\n",
    "    with open(r\"/workspace/hramzr/2_Phd_PROJECT/VarCallingWGS/parliament2_calling/\"+ \\\n",
    "               str(indv.split()[0])+\"/outputs/\"+str(indv.split()[0])+\"_q20.combined.genotyped.vcf\", \"r\") as f:\n",
    "        chrom_dict={}\n",
    "        header_list=[]\n",
    "        for i in range(25):\n",
    "            chrom_dict[\"LG\"+str(i+1)]={'DEL':0, 'DUP':0, 'INS':0, 'INV':0, 'TRA':0, 'BND':0}\n",
    "        for line in f:\n",
    "            if \"#\" not in line:\n",
    "#                 if int(start) and int(end\n",
    "                start=line.split()[1]\n",
    "                if chrom != line.split()[0][3:]:\n",
    "                    bin_size=1\n",
    "                if ((int(start)/1000000)>bin_size):                    \n",
    "                    row=str(chrom_dict[chrom])\n",
    "                    row=re.sub(\"[^0-9]\", \" \", row)\n",
    "                    row=' '.join(row.split())\n",
    "                    headers.write(chrom+\"_dels_\"+str(bin_size*1000000)+\" \"+chrom+\"_dups_\"+str(bin_size*1000000)+\" \"+ \\\n",
    "                          chrom+\"_ins_\"+str(bin_size*1000000)+\" \"+ \\\n",
    "                          chrom+\"_invs_\"+str(bin_size*1000000)+\" \"+ \\\n",
    "                          chrom+\"_tras_\"+str(bin_size*1000000)+\" \" +chrom+\"_bnds_\"+str(bin_size*1000000)+\" \")\n",
    "                    for i in range(25):\n",
    "                        chrom_dict[\"LG\"+str(i+1)]={'DEL':0, 'DUP':0, 'INS':0, 'INV':0, 'TRA':0, 'BND':0}\n",
    "                    bin_size+=1\n",
    "                chrom=line.split()[0][3:]\n",
    "                start=line.split()[1]\n",
    "    break\n",
    "headers.write(\"\\n\")\n",
    "headers.close()\n",
    "                \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import collections\n",
    "import re\n",
    "z = open(\"/workspace/hramzr/2_Phd_PROJECT/VarCallingWGS/vcfmerge/svs_per_chrom\", \"w\")\n",
    "indvs = open(r\"/workspace/hramzr/2_Phd_PROJECT/VarCallingWGS/help_files/indvs\", \"r\")\n",
    "\n",
    "for i in range(25):\n",
    "    if i == 0:\n",
    "        head=str(\"indv \"+\"sex \"+\"LG\"+str(i+1)+\"_\"+\"deletions\"+\" LG\"+str(i+1)+\"_\"+\"duplications\"+ \\\n",
    "         \" LG\"+str(i+1)+\"_\"+\"insertions\"+\" LG\"+str(i+1)+\"_\"+\"inversions\"+ \\\n",
    "         \" LG\"+str(i+1)+\"_\"+\"Translocations\"+\" LG\"+str(i+1)+\"_\"+\"BNDs\"+\" LG\"+str(i+1)+\"_\"+\"sv_length_avg \")\n",
    "    else:\n",
    "        head=str(\"LG\"+str(i+1)+\"_\"+\"deletions\"+\" LG\"+str(i+1)+\"_\"+\"duplications\"+ \\\n",
    "         \" LG\"+str(i+1)+\"_\"+\"insertions\"+\" LG\"+str(i+1)+\"_\"+\"inversions\"+ \\\n",
    "         \" LG\"+str(i+1)+\"_\"+\"Translocations\"+\" LG\"+str(i+1)+\"_\"+\"BNDs\"+\" LG\"+str(i+1)+\"_\"+\"sv_length_avg \")\n",
    "\n",
    "    z.write(head)\n",
    "sex=0\n",
    "for indv in indvs:\n",
    "    \n",
    "    with open(r\"/workspace/hramzr/2_Phd_PROJECT/VarCallingWGS/parliament2_calling/\"+ \\\n",
    "               str(indv.split()[0])+\"/outputs/\"+str(indv.split()[0])+\"_q20.survivor_sorted.vcf\", \"r\") as f:\n",
    "        next(f)\n",
    "        chrom_dict={}\n",
    "        sv_count={}\n",
    "        for i in range(25):\n",
    "            chrom_dict[\"LG\"+str(i+1)]={'DEL':0, 'DUP':0, 'INS':0, 'INV':0, 'TRA':0, 'BND':0, 'sv_length_avg':0}\n",
    "            sv_count[\"LG\"+str(i+1)]=0\n",
    "        for line in f:\n",
    "            if \"#\" not in line:\n",
    "                end=line.split()[7].split(\";\")[6][4:]\n",
    "                chrom=line.split()[0]\n",
    "                start=line.split()[1]\n",
    "                svlen=line.split(\";\")[2][7:]\n",
    "                svtype=line.split(\";\")[3][7:]\n",
    "                chrom_dict[chrom][svtype]+=1\n",
    "                chrom_dict[chrom]['sv_length_avg']+=round(float(svlen))\n",
    "                sv_count[chrom]+=1\n",
    "        z.write(\"\\n\")\n",
    "        if sex <9:\n",
    "            assigned_sex=\"1\"\n",
    "        elif sex <18:\n",
    "            assigned_sex=\"0\"\n",
    "        else:\n",
    "            assigned_sex=\"2\"\n",
    "        for i in range(25):\n",
    "#             print(int(chrom_dict[\"LG\"+str(i+1)]['sv_length_avg']/sv_count[\"LG\"+str(i+1)]))\n",
    "            chrom_dict[\"LG\"+str(i+1)]['sv_length_avg']=int(chrom_dict[\"LG\"+str(i+1)]['sv_length_avg']/sv_count[\"LG\"+str(i+1)])\n",
    "            if i ==0:\n",
    "                line=str(indv)+\" \"+assigned_sex+\" \"+str(chrom_dict[\"LG\"+str(i+1)]).replace(\"{\", \"\").replace(\"}\", \"\").replace(\":\", \"\")\n",
    "            else:\n",
    "                line=str(chrom_dict[\"LG\"+str(i+1)]).replace(\"{\", \"\").replace(\"}\", \"\").replace(\":\", \"\")\n",
    "            row=re.sub(\"[^0-9]\", \" \", line)\n",
    "            row=' '.join(row.split())\n",
    "            print(row)\n",
    "            z.write(row+\" \")  \n",
    "    sex +=1\n",
    "z.close()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#             break\n",
    "#             males=line.split()[9][0:3], line.split()[10][0:3],line.split()[11][0:3],line.split()[12][0:3],line.split()[13][0:3], \\\n",
    "#             line.split()[14][0:3], line.split()[15][0:3], line.split()[16][0:3], line.split()[17][0:3]\n",
    "#             females=line.split()[18][0:3], line.split()[19][0:3], line.split()[20][0:3], line.split()[21][0:3], line.split()[22][0:3], \\\n",
    "#             line.split()[23][0:3], line.split()[24][0:3], line.split()[25][0:3], line.split()[26][0:3]\n",
    "#             if counterM[\"./.\"]>0 and counterF[\"./.\"]<0 or counterM[\"./.\"]<0 and counterF[\"./.\"]>0:\n",
    "#                 print(chrom, start, end, svtype, abs(int(svlen)))\n",
    "#                 print(males, females)\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat svs_per_chrom | tr \"\\n\" \"-\" | tr -s [[:space:]] \",\" | tr \"-\" \"\\n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn import svm\n",
    "import warnings\n",
    "df=pd.read_csv(\"/workspace/hramzr/2_Phd_PROJECT/VarCallingWGS/vcfmerge/svs_per_chrom\", delimiter=\" \")  \n",
    "df=df.loc[:, df.columns != 'Unnamed: 177']\n",
    "df\n",
    "# y = df.sex\n",
    "# x = df.drop(columns=[\"sex\"])\n",
    "# x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.5, random_state=42)\n",
    "\n",
    "# x\n",
    "# ranfor = RandomForestClassifier(n_estimators = 1000, criterion = 'entropy', random_state = 0, max_features = 'auto', max_depth = 1000)\n",
    "# ranfor.fit(x_train, y_train)\n",
    "# pred_ranfor = ranfor.predict(x_test)\n",
    "# print(accuracy_score(y_test, pred_ranfor))\n",
    "# pred_ranfor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "module avail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "module load vcftools/0.1.14\n",
    "\n",
    "# rm id_adjusted.vcf\n",
    "# cat /workspace/hramzr/2_Phd_PROJECT/VarCallingWGS/vcfmerge/9_male_female_merged_samples.vcf \\\n",
    "# | egrep \"#\">id_adjusted.vcf\n",
    "# cat /workspace/hramzr/2_Phd_PROJECT/VarCallingWGS/vcfmerge/9_male_female_merged_samples.vcf \\\n",
    "# | egrep -v \"#\" | awk -F \";\" '{print substr($7,5)\"_\"$0}' | tr \" \" \"\\t\">>id_adjusted.vcf\n",
    "\n",
    "\n",
    "vcftools --vcf /workspace/hramzr/2_Phd_PROJECT/VarCallingWGS/vcfmerge/9_male_female_merged_samples.vcf --extract-FORMAT-info GT --out /workspace/hramzr/2_Phd_PROJECT/VarCallingWGS/vcfmerge/9fm_samples.gt\n",
    "# vcftools --vcf /workspace/hramzr/2_Phd_PROJECT/VarCallingWGS/freebayes/80_Samples_FB.vcf --extract-FORMAT-info GT --out /workspace/hramzr/2_Phd_PROJECT/VarCallingWGS/vcfmerge/80_samples.gt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat /workspace/hramzr/2_Phd_PROJECT/VarCallingWGS/parliament2_calling/275378212/outputs/275378212_q20.survivor_sorted.vcf | egrep -v \"#\" | head"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## -\n",
    "## -\n",
    "## -\n",
    "## -\n",
    "## -\n",
    "## -\n",
    "## -"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Population metrics 9 male 9 female pool of samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlist=$(cat ${out}mergelist | awk -F \"_\" '{print $4}' | awk -F \"/\" '{print $NF}')\n",
    "\n",
    "for value in $mlist\n",
    "do\n",
    "cat /workspace/hramzr/2_Phd_PROJECT/cnv_calling/80_snapper_samples_generations | egrep $value\n",
    "done\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "indvs = open(r\"/workspace/hramzr/2_Phd_PROJECT/VarCallingWGS/help_files/indvs\", \"r\")\n",
    "dict_vars={}\n",
    "chroms=[]\n",
    "for i in range(25):\n",
    "    chroms.append(\"LG\"+str(i+1))\n",
    "\n",
    "for indv in indvs:\n",
    "    vcf = open(r\"/workspace/hramzr/2_Phd_PROJECT/VarCallingWGS/parliament2_calling/\"+ \\\n",
    "               str(indv.split()[0])+\"/outputs/\"+str(indv.split()[0])+\"_q20.survivor_sorted.vcf\", \"r\")\n",
    "    for chrom in chroms:\n",
    "        dict_vars[indv.strip()]={chrom:{'DEL':0, 'DUP':0, 'INS':0, 'INV':0, 'TRA':0, 'BND':0}}\n",
    "    print(dict_vars)\n",
    "\n",
    "    for line in vcf:\n",
    "        if \"#\" not in line:\n",
    "            chrom=line.split(';')[0].split(\"\\t\")[0]\n",
    "            var=line.split(';')[3][7:10]\n",
    "            print(di)\n",
    "            dict_vars[indv.strip()][chrom][var]+=1            \n",
    "            \n",
    "            \n",
    "print(dict_vars['261931510'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "females = open(r\"/workspace/hramzr/2_Phd_PROJECT/VarCallingWGS/help_files/females.lst\", \"r\")\n",
    "males = open(r\"/workspace/hramzr/2_Phd_PROJECT/VarCallingWGS/help_files/males.lst\", \"r\")\n",
    "\n",
    "df = pd.DataFrame([[\"chrom\", ['bp_len']]])\n",
    "for indv in females:\n",
    "    try:\n",
    "        vcf = open(r\"/workspace/hramzr/2_Phd_PROJECT/VarCallingWGS/parliament2_calling/\"+ \\\n",
    "             str(indv.split()[0])+\"/outputs/\"+str(indv.split()[0])+\"_q20.survivor_sorted.vcf\", \"r\")\n",
    "        print (indv)\n",
    "        for line in vcf:\n",
    "            if \"#\" not in line:\n",
    "                 chrom=line.split(';')[0].split(\"\\t\")[0]\n",
    "                 pos=line.split(';')[0].split(\"\\t\")[1]\n",
    "                 var=line.split(';')[0].split(\"\\t\")[4]\n",
    "                 length=line.split(';')[2].split(\"=\")[1]\n",
    "#                  print(chrom,pos,var)  \n",
    "                 \n",
    "#                  row_df = pd.DataFrame([chrom,length])\n",
    "#                  df = pd.concat([row_df, df], ignore_index=True)\n",
    "#                  print (chrom,pos,var,length)\n",
    "                \n",
    "    except:\n",
    "        pass\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "echo \"----male-----\"\n",
    "cat /workspace/hramzr/2_Phd_PROJECT/VarCallingWGS/parliament2_calling/*/outputs/*_q20.survivor_sorted.vcf | egrep -v \"#\" | \\\n",
    "tr \";\" \" \" | awk '{print substr($3,1,3)}' | sort | uniq\n",
    "\n",
    "# echo \"----male2-----\"\n",
    "# cat /workspace/hramzr/2_Phd_PROJECT/VarCallingWGS/parliament2_calling/275378212/outputs/275378212_q20.survivor_sorted.vcf | egrep -v \"#\" | \\\n",
    "# tr \";\" \" \" | awk '{print $1,$2,substr($3,1,3), substr($10,8)}' | awk '{print $3}' | sort | uniq -c\n",
    "\n",
    "# echo \"----male3-----\"\n",
    "# cat /workspace/hramzr/2_Phd_PROJECT/VarCallingWGS/parliament2_calling/734562795/outputs/734562795_q20.survivor_sorted.vcf | egrep -v \"#\" | \\\n",
    "# tr \";\" \" \" | awk '{print $1,$2,substr($3,1,3), substr($10,8)}' | awk '{print $3}' | sort | uniq -c\n",
    "\n",
    "\n",
    "# echo \"----male4-----\"\n",
    "# cat /workspace/hramzr/2_Phd_PROJECT/VarCallingWGS/parliament2_calling/261931510/outputs/261931510_q20.survivor_sorted.vcf | egrep -v \"#\" | \\\n",
    "# tr \";\" \" \" | awk '{print $1,$2,substr($3,1,3), substr($10,8)}' | awk '{print $3}' | sort | uniq -c\n",
    "\n",
    "# echo \"----female-----\"\n",
    "\n",
    "# cat /workspace/hramzr/2_Phd_PROJECT/VarCallingWGS/parliament2_calling/299826357/outputs/299826357_q20.survivor_sorted.vcf | egrep -v \"#\" | \\\n",
    "# tr \";\" \" \" | awk '{print $1,$2,substr($3,1,3), substr($10,8)}' | awk '{print $3}' | sort | uniq -c"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Bash",
   "language": "bash",
   "name": "bash"
  },
  "language_info": {
   "codemirror_mode": "shell",
   "file_extension": ".sh",
   "mimetype": "text/x-sh",
   "name": "bash"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#######################################\n",
    "Function: \n",
    "1. Make a directory for the BAM files that need to be aligned together.\n",
    "2. Make a directory for the BAM files that need to be merged together.\n",
    "3. Make a directory to store errors and output logs for the alignment process.\n",
    "4. Make a directory to store errors and output logs for the merging process.\n",
    "5. Make a directory to store errors and output logs for the duplication removal process.\n",
    "6. Make a directory to store errors and output logs for adding read group IDS.\n",
    "7. Make a directory to store temporary files that are created when running the script processes.\n",
    "#######################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mkdir -p 00.data/alignment_files\n",
    "mkdir -p 00.data/merging_files\n",
    "mkdir -p 02.alignment/log\n",
    "mkdir -p 03.merged_bam_files/log\n",
    "mkdir -p 04.mark_duplicates/log\n",
    "mkdir -p 05.add_read_group_IDs/log\n",
    "mkdir -p tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#######################################\n",
    "Function: \n",
    "1. Extract data from the SQLite database of the reference and fastq data tables.\n",
    "2. Make a ref.tab file to store the path of the reference and the reference filename from the extracted data after trimming \n",
    "these variables of enters and dashes so they are readable as input for process running.\n",
    "3. Make a read_groups.tab file to store group identifiers in after formatting the FASTQ ID to group names.\n",
    "4. Adding these group names to a samples.tab file, along with all trimmed read data from the fastq data table.\n",
    "#######################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Extract ref and fastq data.\n",
    "import sqlite3\n",
    "con = sqlite3.connect(r\"/powerplant/workspace/hramzr/DNAseq_mapping/db_mapping.db\")\n",
    "mycur = con.cursor() \n",
    "mycur.execute(\"SELECT fastq_id,read1_L001_trimmed,read2_L001_trimmed,read1_L002_trimmed,read2_L002_trimmed,trimmed_path FROM fastq_data\")\n",
    "dna_data_file=(mycur.fetchall())\n",
    "mycur.execute(\"SELECT * FROM ref_data\")\n",
    "ref_data_file=(mycur.fetchall())\n",
    "\n",
    "# Make REF tab.\n",
    "f= open(\"00.data/ref.tab\",\"w+\")\n",
    "ref_data_file = str(ref_data_file[0]).split(\",\")\n",
    "IPATH = ref_data_file[1][2:66]\n",
    "INDEX = ref_data_file[2][2:44]\n",
    "f.write(IPATH + \"\\t\" + INDEX +\"\\n\")\n",
    "f.close()\n",
    "            \n",
    "\n",
    "# Make groups tab.\n",
    "f= open(\"00.data/read_groups.tab\", \"w+\")\n",
    "for line in dna_data_file:\n",
    "    FID, R1L1T, R2L1T, R1L2T, R2L2T, TRPTH = line\n",
    "    if FID < 10:\n",
    "        f.write(\"0\" + str(FID) + \"_group\" + \"\\t\" + str(FID) +\"\\n\")    \n",
    "    else:\n",
    "        f.write(str(FID) + \"_group\" + \"\\t\" + str(FID) +\"\\n\")  \n",
    "f.close()            \n",
    "\n",
    "# Retrieve group names.\n",
    "name_list = []\n",
    "with open(\"00.data/read_groups.tab\") as f:\n",
    "   for line in f:\n",
    "        line = line.split(\"\\t\")\n",
    "        name_list.append(line[0])\n",
    "\n",
    "# Make samples tab.\n",
    "f= open(\"00.data/samples.tab\", \"w+\")\n",
    "i=0\n",
    "for line in dna_data_file:\n",
    "    FID, R1L1T, R2L1T, R1L2T, R2L2T, TRPTH = line\n",
    "    f.write(name_list[i] + \"\\t\" + str(FID) + \"\\t\" + R1L1T.strip() +  \"\\t\" + R2L1T.strip() + \"\\t\" + R1L2T.strip()\n",
    "            + \"\\t\" + R2L2T.strip() + \"\\t\"+ TRPTH.strip()+\"\\n\")\n",
    "    i+=1\n",
    "f.close()       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generating merging config files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#######################################\n",
    "Function: \n",
    "Remove existing merging files if they exist and\n",
    "Generate new merging config files by using\n",
    "the group and group number columns from the samples.tab file to store \n",
    "lines with the directory and file that contain the BAM files that need to be merged in order to create 1 animal group.\n",
    "#######################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rm 00.data/merging_files/*.txt \n",
    "\n",
    "while read -r ERRG FID R1L1T R2L1T R1L2T R2L2T TRPTH\n",
    "do      \n",
    "    echo \"02.alignment/${FID}L1_${ERRG}.bam\" >> 00.data/merging_files/${ERRG}.txt\n",
    "    echo \"02.alignment/${FID}L2_${ERRG}.bam\" >> 00.data/merging_files/${ERRG}.txt\n",
    "done < 00.data/samples.tab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set variables and reference file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#######################################\n",
    "Function: \n",
    "1. Load the samtools v1.7, the bwa v0.7.17 and the picard-tools v 2.18.7 modules to use for the alignment,\n",
    "merging, duplication removal and adding read groups processes.\n",
    "2. Set the align directory, for the alignment process.\n",
    "3. Set the merge directory, for the merging process.\n",
    "4. Set the mark duplicates directory, for the duplication removal process.\n",
    "5. Set the add read group directory, for the add read group process.\n",
    "6. Extract the reference sequence directory and filename from the ref.tab file. And set the ref seq directory,\n",
    "to find the reference sequence in the alignment process.\n",
    "#######################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "module load samtools/1.7\n",
    "module load bwa/0.7.17\n",
    "module load picard-tools/2.18.7\n",
    "\n",
    "# Set job to unique 6 characters.\n",
    "\n",
    "ALIGNDIR=02.alignment\n",
    "MERGEDIR=03.merged_bam_files\n",
    "MARKDUPDIR=04.mark_duplicates\n",
    "ADDRGPSDIR=05.add_read_group_IDs\n",
    "\n",
    "while read -r INDEX_DIR INDEX\n",
    "do\n",
    "    INDEX_OUT_TOP_DIR=$INDEX_DIR\n",
    "    IDX_NAME=$INDEX\n",
    "    REFSEQ=${INDEX_OUT_TOP_DIR}/${IDX_NAME}\n",
    "done < 00.data/ref.tab\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run the process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#######################################\n",
    "Function: \n",
    "Set a unique job name for running the specific jobs on a cluster.\n",
    "#######################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ZcL\n"
     ]
    }
   ],
   "source": [
    "job=$(head /dev/urandom | tr -dc A-Za-z0-9 | head -c 3 ; echo '')\n",
    "echo $job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#######################################\n",
    "Input: \n",
    "1. The reference sequence.\n",
    "2. First trimmed reads of the first lane.\n",
    "3. Second trimmed reads of the first lane.\n",
    "4. First trimmed read of the second lane.\n",
    "5. Second trimmed read of the second lane.\n",
    "\n",
    "Function: \n",
    "1. Read the samples.tab file for its trimmed read data, then use this data to align these reads\n",
    "to the reference sequence to create BAM files per lane 1 and 2 belonging to 1 animal group.\n",
    "\n",
    "Output:\n",
    "1. Lane 1 BAM file containing the aligned reads of lane 1.\n",
    "2. Lane 2 BAM file containing the aligned reads of lane 2.\n",
    "#######################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bash: Input:: command not found\n",
      "bash: 1.: command not found\n",
      "bash: 2.: command not found\n",
      "bash: 3.: command not found\n",
      "bash: 4.: command not found\n",
      "bash: 5.: command not found\n",
      "bash: Function:: command not found\n",
      "bash: 1.: command not found\n",
      "bash: to: command not found\n",
      "bash: Output:: command not found\n",
      "bash: 1.: command not found\n",
      "bash: 2.: command not found\n",
      "bash: 00.data/samples.tab: No such file or directory\n"
     ]
    },
    {
     "ename": "",
     "evalue": "1",
     "output_type": "error",
     "traceback": []
    }
   ],
   "source": [
    "#Alignment\n",
    "jobnum=0\n",
    "\n",
    "while read -r ERRG FID R1L1T R2L1T R1L2T R2L2T TRPTH\n",
    "do\n",
    "    bsub \\\n",
    "    -o ${ALIGNDIR}/log/${FID}L1_${ERRG}.out -e ${ALIGNDIR}/log/${FID}L1_${ERRG}.err -n 8 \\\n",
    "    -J \"${job}B${jobnum}\" \\\n",
    "    \"bwa mem -t 8 \\\n",
    "    ${REFSEQ} ${TRPTH}/${R1L1T} ${TRPTH}/${R2L1T}\\\n",
    "    | samtools view -Su - | samtools sort - -o ${ALIGNDIR}/${FID}L1_${ERRG}.bam\"\n",
    "    jobnum=$((jobnum + 1))\n",
    "    \n",
    "    \n",
    "    bsub \\\n",
    "    -o ${ALIGNDIR}/log/${FID}L2_${ERRG}.out -e ${ALIGNDIR}/log/${FID}L2_${ERRG}.err -n 8 \\\n",
    "    -J \"${job}B${jobnum}\" \\\n",
    "    \"bwa mem -t 8 \\\n",
    "    ${REFSEQ} ${TRPTH}/${R1L2T} ${TRPTH}/${R2L2T}\\\n",
    "    | samtools view -Su - | samtools sort - -o ${ALIGNDIR}/${FID}L2_${ERRG}.bam\"\n",
    "    jobnum=$((jobnum + 1))\n",
    "    \n",
    "done < 00.data/samples.tab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#######################################\n",
    "Input: \n",
    "Lane 1 and lane 2 BAM files.\n",
    "\n",
    "Function: \n",
    "Merge the two lane BAM files created in alignment in one BAM file named after the corresponding animal group.\n",
    "\n",
    "Output:\n",
    "Merged BAM file beloning to 1 animal group.\n",
    "#######################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Merging, note that using -f to force in case directory isn't clear of previous files\n",
    "while read -r ERRG LINE R1L1T R2L1T R1L2T R2L2T TRPTH\n",
    "do\n",
    "    FILE=00.data/merging_files/${ERRG}.txt\n",
    "    bsub -w \"done(${job}B*)\" -o ${MERGEDIR}/log/${ERRG}.out -e ${MERGEDIR}/log/${ERRG}.err -n 8 -J \"${job}C${LINE}\" \\\n",
    "    \"samtools merge -f -b $FILE ${MERGEDIR}/${ERRG}.bam\"\n",
    "done < 00.data/samples.tab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#######################################\n",
    "Input: \n",
    "Animal group BAM files.\n",
    "\n",
    "Function: \n",
    "Remove duplicates left over from PCR to mitigate variant call biases.\n",
    "\n",
    "Output:\n",
    "Animal group BAM files with duplicates removed.\n",
    "#######################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Remove duplicates.\n",
    "PICARD=/software/bioinformatics/picard-tools-2.18.7/picard.jar\n",
    "while read -r ERRG LINE R1L1T R2L1T R1L2T R2L2T TRPTH\n",
    "do\n",
    "    bsub -w \"done(${job}C${LINE})\" -o ${MARKDUPDIR}/log/${ERRG}.out -e ${MARKDUPDIR}/log/${ERRG}.err -n 8 -J \"${job}D${LINE}\" \\\n",
    "    -R \"rusage[mem=40800] span[hosts=1]\" \\\n",
    "    \"java -jar -Xmx32G -Djava.io.tmpdir=`pwd`/tmp $PICARD MarkDuplicates \\\n",
    "    INPUT=${MERGEDIR}/${ERRG}.bam \\\n",
    "    OUTPUT=${MARKDUPDIR}/${ERRG}.bam \\\n",
    "    AS=true \\\n",
    "    MAX_RECORDS_IN_RAM=500000 \\\n",
    "    MAX_FILE_HANDLES=1000 \\\n",
    "    M=${MARKDUPDIR}/${ERRG}.txt \\\n",
    "    OPTICAL_DUPLICATE_PIXEL_DISTANCE=2500 \\\n",
    "    TMP_DIR=`pwd`/tmp \\\n",
    "    REMOVE_DUPLICATES=true\"\n",
    "done < 00.data/samples.tab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#######################################\n",
    "Input: \n",
    "Animal group BAM files with duplicates removed.\n",
    "\n",
    "Function: \n",
    "Add read group data in order to distinguish read origin when variant calling.\n",
    "\n",
    "Output:\n",
    "Animal group BAM files with duplicates removed and read groups added.\n",
    "#######################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job <40373> is submitted to default queue <normal>.\n",
      "Job <40374> is submitted to default queue <normal>.\n",
      "Job <40375> is submitted to default queue <normal>.\n",
      "Job <40376> is submitted to default queue <normal>.\n",
      "Job <40377> is submitted to default queue <normal>.\n",
      "Job <40378> is submitted to default queue <normal>.\n",
      "Job <40379> is submitted to default queue <normal>.\n",
      "Job <40380> is submitted to default queue <normal>.\n",
      "Job <40381> is submitted to default queue <normal>.\n",
      "Job <40382> is submitted to default queue <normal>.\n",
      "Job <40383> is submitted to default queue <normal>.\n",
      "Job <40384> is submitted to default queue <normal>.\n",
      "Job <40385> is submitted to default queue <normal>.\n"
     ]
    }
   ],
   "source": [
    "# Add read groups.\n",
    "PICARD=/software/bioinformatics/picard-tools-2.18.7/picard.jar\n",
    "while read -r ERRG LINE R1L1T R2L1T R1L2T R2L2T TRPTH\n",
    "do\n",
    "    bsub \\\n",
    "    -m wkoppb37 \\\n",
    "    -o ${ADDRGPSDIR}/log/${ERRG}.out -e ${ADDRGPSDIR}/log/${ERRG}.err -n 8 -J \"${job}E${LINE}\" \\\n",
    "    \"java -jar -Xmx32G -Djava.io.tmpdir=`pwd`/tmp $PICARD AddOrReplaceReadGroups \\\n",
    "    I=${MARKDUPDIR}/${ERRG}.bam \\\n",
    "    O=${ADDRGPSDIR}/${ERRG}.bam \\\n",
    "    MAX_RECORDS_IN_RAM=500000 \\\n",
    "    RGID=${ERRG} \\\n",
    "    RGLB=lib1 \\\n",
    "    RGPL=Illumina \\\n",
    "    RGPU=unit1 \\\n",
    "    RGSM=${ERRG}\"\n",
    "done < 00.data/samples.tab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#######################################\n",
    "Input: \n",
    "Animal group BAM files with duplicates removed and read groups added.\n",
    "\n",
    "Function: \n",
    "Index the BAM files to use for further processing.\n",
    "\n",
    "Output:\n",
    "Indexed BAM files.\n",
    "#######################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job <41411> is submitted to default queue <normal>.\n",
      "Job <41412> is submitted to default queue <normal>.\n",
      "Job <41413> is submitted to default queue <normal>.\n",
      "Job <41414> is submitted to default queue <normal>.\n",
      "Job <41415> is submitted to default queue <normal>.\n",
      "Job <41416> is submitted to default queue <normal>.\n",
      "Job <41417> is submitted to default queue <normal>.\n",
      "Job <41418> is submitted to default queue <normal>.\n",
      "Job <41419> is submitted to default queue <normal>.\n",
      "Job <41420> is submitted to default queue <normal>.\n",
      "Job <41421> is submitted to default queue <normal>.\n",
      "Job <41422> is submitted to default queue <normal>.\n",
      "Job <41423> is submitted to default queue <normal>.\n"
     ]
    }
   ],
   "source": [
    "while read -r ERRG LINE R1L1T R2L1T R1L2T R2L2T TRPTH\n",
    "do\n",
    "    bsub  -J \"${job}F${LINE}\" -o ${ADDRGPSDIR}/log/I${ERRG}.out -e ${ADDRGPSDIR}/log/I${ERRG}.err \"samtools index ${ADDRGPSDIR}/${ERRG}.bam\"\n",
    "done < 00.data/samples.tab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#######################################\n",
    "Function: \n",
    "Check the jobs running on the cluster to see the status of the script running.\n",
    "#######################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JOBID   USER    STAT  QUEUE      FROM_HOST   EXEC_HOST   JOB_NAME   SUBMIT_TIME\n",
      "30603   hramzr  RUN   normal     aklppj31    wkoppb43    iUdF1      Oct 10 10:36\n",
      "30604   hramzr  RUN   normal     aklppj31    wkoppb43    iUdF2      Oct 10 10:36\n",
      "30605   hramzr  RUN   normal     aklppj31    wkoppb43    iUdF3      Oct 10 10:36\n",
      "30606   hramzr  RUN   normal     aklppj31    wkoppb43    iUdF4      Oct 10 10:36\n",
      "30607   hramzr  RUN   normal     aklppj31    wkoppb43    iUdF5      Oct 10 10:36\n",
      "30608   hramzr  RUN   normal     aklppj31    wkoppb43    iUdF6      Oct 10 10:36\n",
      "30609   hramzr  RUN   normal     aklppj31    wkoppb43    iUdF7      Oct 10 10:36\n",
      "30610   hramzr  RUN   normal     aklppj31    wkoppb43    iUdF8      Oct 10 10:36\n",
      "30611   hramzr  RUN   normal     aklppj31    wkoppb43    iUdF9      Oct 10 10:36\n",
      "30612   hramzr  RUN   normal     aklppj31    wkoppb43    iUdF10     Oct 10 10:36\n",
      "30613   hramzr  RUN   normal     aklppj31    wkoppb37    iUdF11     Oct 10 10:36\n",
      "30614   hramzr  RUN   normal     aklppj31    wkoppb37    iUdF12     Oct 10 10:36\n",
      "30615   hramzr  RUN   normal     aklppj31    wkoppb37    iUdF13     Oct 10 10:36\n"
     ]
    }
   ],
   "source": [
    "bjobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#######################################\n",
    "Function: \n",
    "Kill jobs, incase something goes wrong.\n",
    "#######################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bkill 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#######################################\n",
    "Function: \n",
    "Check available hosts to use.\n",
    "#######################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HOST_NAME          STATUS       JL/U    MAX  NJOBS    RUN  SSUSP  USUSP    RSV \n",
      "aklppb31           closed          -     10     10     10      0      0      0\n",
      "aklppb32           closed          -     10     10     10      0      0      0\n",
      "aklppb34           ok              -    160     80     80      0      0      0\n",
      "aklppb35           closed          -      8      8      8      0      0      0\n",
      "aklppb36           ok              -     40     24     24      0      0      0\n",
      "aklppb37           closed          -     10     10     10      0      0      0\n",
      "aklppb40           ok              -     10      0      0      0      0      0\n",
      "aklppb41           ok              -     10      1      1      0      0      0\n",
      "aklppb42           ok              -     10      3      3      0      0      0\n",
      "aklppb43           ok              -     10      3      3      0      0      0\n",
      "aklppb44           ok              -     10      8      8      0      0      0\n",
      "aklppf31           closed          -      0      0      0      0      0      0\n",
      "aklppf32           closed          -      0      0      0      0      0      0\n",
      "aklppf33           closed          -      0      0      0      0      0      0\n",
      "aklppj31           closed          -      0      0      0      0      0      0\n",
      "aklppr31           closed          -      0      0      0      0      0      0\n",
      "wkoppb31           ok              -     32      1      1      0      0      0\n",
      "wkoppb32           closed          -     32      0      0      0      0      0\n",
      "wkoppb33           ok              -     32      0      0      0      0      0\n",
      "wkoppb34           ok              -     32      1      1      0      0      0\n",
      "wkoppb35           closed          -     32     32     32      0      0      0\n",
      "wkoppb36           ok              -     32      0      0      0      0      0\n",
      "wkoppb37           ok              -     80      0      0      0      0      0\n",
      "wkoppb38           ok              -     80      4      4      0      0      0\n",
      "wkoppb39           ok              -     80      2      2      0      0      0\n",
      "wkoppb40           closed          -     10     10     10      0      0      0\n",
      "wkoppb41           closed          -     10     10     10      0      0      0\n",
      "wkoppb42           ok              -     10      1      1      0      0      0\n",
      "wkoppb43           ok              -     10      2      2      0      0      0\n",
      "wkoppb44           closed          -     10     10     10      0      0      0\n",
      "wkoppb50           ok              -     96     18     18      0      0      0\n",
      "wkoppg31           ok              -     96     18     18      0      0      0\n",
      "wkoppg32           ok              -     96      1      1      0      0      0\n",
      "wkoppg33           ok              -     96     20     20      0      0      0\n",
      "wkoppg34           ok              -     96     48     48      0      0      0\n"
     ]
    }
   ],
   "source": [
    "bhosts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#######################################\n",
    "Function: \n",
    "Check directory.\n",
    "#######################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/powerplant/workspace/hramzr/DNAseq_mapping/alignment\n"
     ]
    }
   ],
   "source": [
    "pwd"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Bash",
   "language": "bash",
   "name": "bash"
  },
  "language_info": {
   "codemirror_mode": "shell",
   "file_extension": ".sh",
   "mimetype": "text/x-sh",
   "name": "bash"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
